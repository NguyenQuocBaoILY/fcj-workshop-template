[{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/4-eventparticipated/4.1-event1/","title":"Sự kiện 1","tags":[],"description":"","content":"AWS Cloud Mastery Series #1 - AI/ML/GenAI on AWS Workshop 1. Thông tin sự kiện Tên sự kiện: AWS Cloud Mastery Series #1 - AI/ML/GenAI on AWS Workshop Thời gian: 8:30 – 12:00 Đơn vị tổ chức: Amazon Web Services (AWS) 2. Mục đích tham dự Tôi tham dự sự kiện nhằm nắm bắt hệ sinh thái AI/ML/GenAI trên AWS, hiểu rõ vòng đời ML end-to-end với SageMaker, cách vận hành Foundation Models trên Amazon Bedrock, tiếp cận Prompt Engineering, RAG và Agents, đồng thời quan sát quy trình xây dựng một GenAI chatbot thực tế.\n3. Tóm tắt nội dung theo Agenda 8:30 – 9:00 — Check-in \u0026amp; Introduction Hoạt động chính:\nCheck-in và networking Giới thiệu mục tiêu workshop Ice-breaker Tổng quan thị trường AI/ML tại Việt Nam Điểm chính:\nNắm được bức tranh AI/ML trong doanh nghiệp Việt Nam và vai trò của AWS trong thúc đẩy chuyển đổi số bằng ML và GenAI.\n9:00 – 10:30 — AWS AI/ML Services Overview Nội dung:\nGiới thiệu Amazon SageMaker – nền tảng ML end-to-end Chuẩn bị \u0026amp; gán nhãn dữ liệu Huấn luyện, tuning và deployment mô hình MLOps tích hợp trong SageMaker Live Demo: SageMaker Studio Điểm chính:\nHiểu rõ vòng đời phát triển ML trên AWS, từ chuẩn bị dữ liệu → train → tune → deploy, kèm trải nghiệm thực tế trên SageMaker Studio.\n10:30 – 10:45 — Coffee Break Thời gian trao đổi, đặt câu hỏi và networking với chuyên gia AWS.\n10:45 – 12:00 — Generative AI with Amazon Bedrock Nội dung:\nFoundation Models: Claude, Llama, Titan – khác biệt \u0026amp; cách chọn Prompt Engineering: CoT, Few-shot RAG: kiến trúc, tích hợp Knowledge Base Bedrock Agents: multi-step workflows, tool integration Guardrails: bộ lọc, tiêu chuẩn an toàn nội dung Live Demo: xây dựng chatbot GenAI Điểm chính:\nHiểu cách chọn mô hình, viết prompt hiệu quả, xây RAG, dùng Agents, đảm bảo Guardrails, và toàn bộ quy trình tạo chatbot GenAI bằng Bedrock.\nNhững điểm chính rút ra Hiểu toàn diện AI/ML/GenAI trên AWS Phân biệt và chọn Foundation Models (Claude/Llama/Titan) Ứng dụng Chain-of-Thought \u0026amp; Few-shot để nâng chất lượng output Thiết kế prompt cho tác vụ phức tạp Hiểu nhu cầu của RAG trong ứng dụng doanh nghiệp Xây dựng Agents với tool integrations Nắm rõ ML lifecycle và MLOps qua SageMaker Studio Biết cách deploy GenAI chatbots theo tiêu chuẩn AWS Khả năng áp dụng thực tế Áp dụng RAG vào chatbot nội bộ hoặc hệ thống hỗ trợ tài liệu Dùng SageMaker để train/fine-tune mô hình ML Tối ưu kết quả FM bằng Prompt Engineering Dùng Bedrock Agents để tự động hóa workflow Xây dựng GenAI proof-of-concept cho team Trải nghiệm sự kiện Sự kiện mang lại trải nghiệm thực tế và giúp tôi hiểu sâu hơn cách doanh nghiệp triển khai AI/ML và GenAI.\nCác phiên demo của AWS làm rõ quy trình train → tune → deploy và cách xây dựng ứng dụng GenAI trên Bedrock.\nNhững điểm nổi bật Chuyên gia AWS: phân tích rõ roadmap AI/ML, demo thực tế SageMaker và Bedrock Hands-on demos: quan sát trực tiếp toàn bộ workflow ML và chatbot GenAI Networking: trao đổi case study thực tế với AWS engineers và các học viên Bài học: GenAI không chỉ là mô hình mà là workflow hoàn chỉnh (Prompt → RAG → Agents → Guardrails); SageMaker chuẩn hóa lifecycle ML; lựa chọn Foundation Model ảnh hưởng mạnh đến chi phí và hiệu quả. Bài học quan trọng GenAI đòi hỏi workflow đầy đủ, không chỉ prompt RAG giúp doanh nghiệp đưa dữ liệu thực vào mô hình Agents giúp mở rộng khả năng tự động hóa SageMaker giúp quy trình ML bài bản và bền vững Việc chọn Foundation Model quyết định latency, cost và accuracy Hình ảnh sự kiện "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Quốc Bảo\nSố điện thoại: 0908439694\nEmail: Baonqse183321@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Công nghệ thông tin\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Tuần 1: Làm quen với AWS và các dịch vụ AWS cơ bản\nTuần 2: Học và thực hành AWS VPC, Networking và kết nối Multi-VPC\nTuần 3: Học Amazon EC2, Backup, Storage Gateway và các kiến thức nền tảng về S3\nTuần 4: VM Import/Export và Amazon FSx cho Windows File Server\nTuần 5: Bảo mật AWS, Tags và IAM Permission Boundaries\nTuần 6: Bảo mật AWS \u0026amp; Phân tích dữ liệu cơ bản\nTuần 7: Hạ tầng AWS \u0026amp; Lập kế hoạch dự án\nTuần 8: Ôn tập giữa kỳ \u0026amp; Luyện thi AWS Cloud Practitioner\nTuần 9: Phát triển dự án \u0026amp; Tổng quan dịch vụ bảo mật AWS\nTuần 10: Phát triển dự án \u0026amp; Giao diện Web\nTuần 11: Tiếp tục phát triển dự án \u0026amp; Giao diện Web\nTuần 12: Triển khai dự án trên AWS\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục Tiêu Tuần 1: Kết nối và làm quen với các thành viên của First Cloud Journey. Hiểu các dịch vụ AWS cơ bản, cách sử dụng console. Các Tác Vụ Thực Hiện Trong Tuần: Ngày Tác vụ Ngày Bắt Đầu Ngày Hoàn Thành Tài liệu Tham Khảo 2 - Tham gia buổi Kick-off AWS FCJ Workforce, hiểu rõ hơn về hạ tầng AWS - Đọc và ghi chú các quy tắc, quy định của đơn vị thực tập 09/06/2025 09/08/2025 3 - Tạo Tài khoản và Thiết lập Thanh toán + Tạo tài khoản AWS mới + Thiết lập MFA cho Tài khoản AWS 09/09/2025 09/09/2025 https://000001.awsstudygroup.com/vi/3-create-admin-user-and-group// 4 - Tìm hiểu về Identity and Access Management (IAM) - Thực hành: + Tạo nhóm quản trị (admin group) và nhóm người dùng (user group) 09/10/2025 09/10/2025 https://000001.awsstudygroup.com/vi/3-create-admin-user-and-group/ 5 - Tìm hiểu về Ngân sách (Budget) - Thực hành: + Tạo Ngân sách bằng Template + Tạo Ngân sách Chi phí (Cost Budget) + Tạo Ngân sách Sử dụng (Usage Budget) trong AWS + Tạo Ngân sách Phiên bản Đặt trước (RI) 09/11/2025 09/11/2025 https://000007.awsstudygroup.com/vi/ 6 - Tìm hiểu về Gói Hỗ trợ AWS (Support Packages) Thực hành: + Các loại yêu cầu hỗ trợ + Thay đổi gói hỗ trợ + Quản lý yêu cầu hỗ trợ 09/12/2025 09/12/2025 hhttps://000009.awsstudygroup.com/vi/ Thành Tựu Tuần 1: Dự án \u0026amp; Tuân thủ: Đã tham gia Kick-off, nắm bắt định hướng dự án và các quy tắc thực tập, đồng thời làm quen với các thành viên FCJ. Thiết lập Cơ bản AWS: Đã tạo và cấu hình tài khoản AWS Free Tier một cách an toàn và thành công. Nền tảng Bảo mật: Đã thiết lập thành công MFA cho Người dùng Root và tạo các IAM Admin/User Groups, áp dụng các nguyên tắc bảo mật cơ bản. Quản lý Chi phí: Đã thực hành tạo AWS Budgets để theo dõi và kiểm soát chi phí ngay từ ban đầu. Hỗ trợ \u0026amp; Dịch vụ: Đã hiểu được các loại Gói Hỗ trợ AWS (Support Packages) và cách quản lý các yêu cầu hỗ trợ. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Xây dựng nền tảng TaskHub theo mô hình DevSecOps trên AWS Giới thiệu Workshop Trong workshop này, bạn sẽ thực hành xây dựng toàn bộ nền tảng TaskHub theo mô hình AWS Serverless + DevSecOps, dựa trên kiến trúc thực tế được các doanh nghiệp áp dụng để triển khai hệ thống linh hoạt, bảo mật và tối ưu chi phí.\nWorkshop được phân chia theo từng nhóm dịch vụ AWS, giúp bạn:\nHiểu vai trò từng dịch vụ trong kiến trúc serverless hiện đại. Tự tay triển khai API Gateway, Lambda, DynamoDB, Cognito, S3/CloudFront. Tiếp cận DevSecOps chuyên nghiệp thông qua CodePipeline, CodeBuild và CodeGuru. Triển khai bảo mật ở cả Backend (KMS, Secrets Manager) và Edge (WAF, Shield). Kết nối hoàn chỉnh frontend Next.js với backend serverless AWS. Tổng quan kiến trúc được triển khai Trong workshop này, bạn sẽ thiết lập toàn bộ các thành phần chính của nền tảng TaskHub:\nAmazon S3 – Lưu trữ build tĩnh của ứng dụng Next.js. Amazon CloudFront – Phân phối giao diện toàn cầu với độ trễ thấp. AWS WAF \u0026amp; AWS Shield – Bảo vệ ứng dụng khỏi tấn công DDoS và OWASP Top 10. Amazon Cognito – Xác thực, quản lý người dùng, phân quyền Admin/Member. Amazon API Gateway – Cổng tiếp nhận request từ frontend. AWS Lambda (Node.js/TypeScript) – Xử lý toàn bộ logic nghiệp vụ. Amazon DynamoDB – Lưu dữ liệu nhiệm vụ, người dùng, tiến độ. AWS KMS – Mã hóa dữ liệu tại DynamoDB. AWS Secrets Manager – Lưu trữ bí mật và khóa API. AWS CodePipeline – Tự động hóa toàn bộ CI/CD. AWS CodeBuild – Build frontend/backend và chạy Security Scan. AWS CodeGuru Reviewer – Phân tích chất lượng mã và đề xuất tối ưu. AWS CloudFormation – Triển khai hạ tầng theo IaC. Amazon CloudWatch Logs – Ghi nhận log từ Lambda và API Gateway. AWS X-Ray – Phân tích độ trễ và tracing toàn hệ thống. Amazon SNS – Gửi thông báo sự kiện hoặc cảnh báo. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.8-cognito/5.8.1-create-user-pool/","title":"Tạo Cognito User Pool","tags":[],"description":"","content":"Tạo User Pool Trong bước này, bạn sẽ tạo một Cognito User Pool để quản lý xác thực người dùng cho ứng dụng của mình.\nĐiều hướng đến dịch vụ AWS Cognito trong AWS Console Nhấp Create user pool Cấu hình tùy chọn (Configure options)\nOptions for sign-in identifiers:\nChọn Email (cho phép người dùng đăng nhập bằng email) Bỏ chọn Phone number và Username Self-registration:\n✅ Enable self-registration (cho phép người dùng tự đăng ký) Required attributes for sign-up:\nChọn email và name làm thuộc tính bắt buộc Nhấp Create user pool Nhập tên User Pool\nUser pool name: TaskManagementUserPool Nhấp Create user pool Xác minh việc tạo User Pool Sau khi tạo thành công, bạn sẽ thấy User Pool của mình trong Cognito console với cấu hình mặc định:\nKiểm tra cấu hình mặc định Cognito sẽ tự động tạo User Pool với các cấu hình mặc định:\nSign-in experience:\nSign-in options: Username (có thể thay đổi thành Email) Password policy: Cognito defaults Multi-factor authentication: Optional Sign-up experience:\nSelf-service sign-up: Enabled Email verification: Enabled Required attributes: email Message delivery:\nEmail provider: Send email with Cognito App integration:\nHosted UI: Not configured (sẽ cấu hình ở bước sau) Ghi chú quan trọng ⚠️ Lưu ý: Các tùy chọn sign-in identifiers và required attributes không thể thay đổi sau khi tạo User Pool. Nếu cần thay đổi, bạn phải tạo User Pool mới.\nGhi chú lại User Pool ID từ trang tổng quan vì bạn sẽ cần nó cho các bước tiếp theo:\nTrong các bước tiếp theo, chúng ta sẽ cấu hình chi tiết các tính năng như password policies, email verification và tạo App Client.\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Cách Patronus AI Giúp Doanh Nghiệp Nâng Cao Độ Tin Cậy Khi Sử Dụng Generative AI bởi Aditya Shahani và Bonnie McClure | vào NGÀY 02 THÁNG 5, 2024 | trong Giải pháp Khách hàng, Generative AI, Startup\nTrong những năm gần đây, đặc biệt kể từ khi ChatGPT ra mắt năm 2022, tiềm năng mang tính thay đổi của Generative AI đã trở nên không thể phủ nhận đối với các tổ chức thuộc mọi quy mô và trong nhiều ngành nghề. Làn sóng tiếp theo của quá trình ứng dụng đã bắt đầu, khi các doanh nghiệp đang nhanh chóng triển khai các công cụ Generative AI để tăng hiệu quả và cải thiện trải nghiệm khách hàng. Theo Báo cáo McKinsey 2023, Generative AI có thể đóng góp thêm từ 2,6 đến 4,4 nghìn tỷ USD cho nền kinh tế toàn cầu mỗi năm, làm tăng tác động kinh tế tổng thể của AI khoảng 15–40%. Bên cạnh đó, khảo sát CEO toàn cầu mới nhất của IBM cho thấy 50% người tham gia đã bắt đầu tích hợp Generative AI vào sản phẩm và dịch vụ của họ.\nTuy nhiên, khi Generative AI trở nên phổ biến, khách hàng và doanh nghiệp ngày càng lo ngại về tính tin cậy của công nghệ này. Ngoài ra, cũng thường không rõ lý do vì sao đầu vào cụ thể lại tạo ra những đầu ra nhất định, khiến các công ty khó đánh giá một cách chính xác kết quả mà Generative AI tạo ra. Patronus AI, do các chuyên gia học máy (ML) Anand Kannappan và Rebecca Qian sáng lập, đã đặt mục tiêu giải quyết vấn đề này. Với nền tảng đánh giá và bảo mật tự động dựa trên AI, Patronus giúp khách hàng sử dụng các mô hình ngôn ngữ lớn (LLM) một cách tự tin và có trách nhiệm, đồng thời giảm thiểu rủi ro sai sót. Mục tiêu của startup là nâng cao tính đáng tin cậy và khả năng sử dụng của các mô hình AI. Anand cho biết: “Đó là câu hỏi lớn nhất trong năm qua. Mọi doanh nghiệp đều muốn sử dụng mô hình ngôn ngữ, nhưng họ lo ngại về rủi ro và cả độ tin cậy của chúng, đặc biệt trong các tình huống đặc thù của doanh nghiệp.” Anh nói thêm: “Sứ mệnh của chúng tôi là tăng cường sự tự tin của doanh nghiệp khi ứng dụng Generative AI.”\nTận dụng lợi ích và quản lý rủi ro khi dùng Generative AI Generative AI là một dạng AI sử dụng ML để tạo ra dữ liệu mới giống với dữ liệu đã được dùng để huấn luyện. Bằng cách học các mẫu và cấu trúc của dữ liệu đầu vào, nó có thể tạo ra nội dung nguyên bản — như hình ảnh, văn bản, hay thậm chí mã lập trình. Các ứng dụng Generative AI được vận hành bởi các mô hình đã được huấn luyện trước trên lượng dữ liệu khổng lồ, đặc biệt là các LLM được huấn luyện trên hàng nghìn tỷ từ.\nLợi ích kinh doanh mà Generative AI mang lại là vô cùng lớn. Nhiều công ty đang quan tâm đến việc sử dụng LLM để khai thác dữ liệu nội bộ thông qua tìm kiếm, tạo memo hoặc bài thuyết trình, cải thiện chatbot tự động, hoặc hỗ trợ viết mã. Anand cũng cho biết còn rất nhiều ngành chưa được \u0026ldquo;chạm tới\u0026rdquo; bởi Generative AI. “Chúng ta mới chỉ ở giai đoạn đầu của những gì có thể đạt được.”\nKhi doanh nghiệp mở rộng ứng dụng Generative AI, vấn đề tin cậy trở nên cấp thiết hơn. Người dùng muốn đảm bảo rằng đầu ra của mô hình tuân thủ quy định và chính sách nội bộ, đồng thời không dẫn đến các kết quả sai lệch hoặc nguy hiểm. Anand chia sẻ: “Đối với các công ty lớn, đặc biệt trong những ngành bị quản lý nghiêm ngặt, có nhiều tình huống mang tính sống còn. Họ muốn sử dụng Generative AI nhưng lo rằng chỉ một sai sót cũng có thể làm tổn hại đến thương hiệu hoặc gây rủi ro cho khách hàng.”\nPatronus giúp khách hàng quản lý rủi ro bằng cách cải thiện khả năng đo lường và phân tích hiệu năng mô hình. “Điều quan trọng là phải đảm bảo quy trình kiểm thử và đánh giá phải thật sự vững chắc và chuẩn hóa,” Anand nói. “Hiện tại vẫn chưa có một khuôn khổ tiêu chuẩn nào để kiểm thử mô hình ngôn ngữ một cách khoa học.”\nNâng cao độ tin cậy và hiệu suất Nền tảng tự động của Patronus giúp khách hàng đánh giá và so sánh hiệu suất của nhiều mô hình LLM trong các tình huống thực tế, giảm nguy cơ sinh ra đầu ra không mong muốn. Patronus sử dụng các kỹ thuật ML mới để tự động tạo bộ kiểm thử đối kháng và chấm điểm mô hình dựa trên hệ thống tiêu chí độc quyền. Ví dụ, bộ dữ liệu FinanceBench là bộ benchmark đầu tiên đo hiệu suất LLM trên các câu hỏi tài chính.\n“Mọi thứ chúng tôi làm đều hướng tới việc giúp các công ty phát hiện lỗi mô hình ở quy mô lớn và hoàn toàn tự động,” Anand nói. Hiện nay, nhiều doanh nghiệp đang phải chi những khoản rất lớn cho đội ngũ QA nội bộ và tư vấn bên ngoài — những người phải tạo test case thủ công và chấm điểm bằng bảng tính. Cách tiếp cận của Patronus giúp loại bỏ quy trình tốn kém đó.\nAnand giải thích: “Xử lý ngôn ngữ tự nhiên là lĩnh vực rất thực nghiệm, nên chúng tôi phải thử nghiệm liên tục để tìm ra kỹ thuật đánh giá tối ưu nhất.” Anh nhấn mạnh mục tiêu là giúp doanh nghiệp dễ dàng tận dụng các kỹ thuật này để cải thiện hiệu suất — cả trong mô hình của họ lẫn quá trình đánh giá mô hình.\nMột vòng tròn cải thiện liên tục được tạo ra: doanh nghiệp càng sử dụng nhiều và phản hồi nhiều, các đánh giá càng chính xác hơn, và hệ thống nội bộ của doanh nghiệp cũng cải thiện theo.\nTăng cường sự tự tin thông qua kết quả tốt hơn và khả năng hiểu mô hình Để khai thác hết tiềm năng của Generative AI, việc nâng cao độ tin cậy và tính giải thích của mô hình là cực kỳ quan trọng. Nhiều doanh nghiệp đang gặp khó khăn không chỉ vì mô hình đôi khi sai mà còn vì không hiểu được tại sao sai, và làm sao để tránh lặp lại.\nAnand nói: “Điều mọi người muốn là một cách để tự tin hơn khi đưa hệ thống vào sản xuất. Khi bạn cho nhân viên hay khách hàng sử dụng, đó có thể là hàng nghìn người. Bạn muốn hạn chế tối đa rủi ro. Và khi lỗi xảy ra, bạn muốn biết nguyên nhân.”\nMột trong những mục tiêu lớn của Patronus là tăng khả năng giải thích — hiểu được tại sao mô hình đưa ra kết quả như vậy và làm thế nào để cải thiện. Patronus cung cấp lời giải thích bằng ngôn ngữ tự nhiên cho từng test case, giúp khách hàng nhanh chóng hiểu nguyên nhân thất bại và nhận các gợi ý cải thiện prompt hoặc tham số mô hình.\nHướng đến tương lai của Generative AI cùng AWS Ngay từ đầu, Patronus đã xây dựng ứng dụng của mình trên AWS. Công ty sử dụng nhiều dịch vụ cloud như Amazon SQS cho hạ tầng hàng đợi và Amazon EC2 cho môi trường Kubernetes, đồng thời tận dụng sự tùy chỉnh linh hoạt của Amazon EKS.\nNhờ kinh nghiệm lâu năm làm việc với AWS trước khi sáng lập Patronus, Anand và nhóm của ông có thể nhanh chóng phát triển sản phẩm và hạ tầng. Patronus cũng hợp tác chặt chẽ với đội ngũ AWS chuyên hỗ trợ startup. Anand chia sẻ: “Tư duy lấy khách hàng làm trung tâm của AWS luôn tuyệt vời, và chúng tôi rất trân trọng điều đó.”\nPatronus hiện đang lạc quan hướng về tương lai, sau khi ra mắt và thu hút được sự quan tâm lớn cùng nguồn vốn hạt giống 3 triệu USD từ Lightspeed Venture Partners. Nhóm cũng đã công bố benchmark đầu tiên về hiệu suất LLM trong các câu hỏi tài chính — hợp tác thiết kế cùng 15 chuyên gia trong ngành.\nAnand nói: “Chúng tôi rất hào hứng với những gì sắp tới. Chúng tôi sẽ tiếp tục tập trung vào đánh giá và kiểm thử AI, giúp doanh nghiệp xác định điểm yếu trong mô hình, đo lường hiệu suất và cuối cùng là xây dựng những sản phẩm đáng tin cậy hơn.”\nVề các tác giả Aditya Shahani Aditya Shahani là Kiến trúc sư Giải pháp dành cho Startup, tập trung hỗ trợ các startup giai đoạn đầu tăng tốc hành trình xây dựng trên AWS. Anh đam mê sử dụng công nghệ mới để giải quyết các vấn đề kinh doanh ở quy mô lớn. Bonnie McClure Bonnie là biên tập viên chuyên tạo nội dung dễ tiếp cận và thu hút cho mọi đối tượng và nền tảng. Cô cam kết mang đến trải nghiệm người dùng mượt mà thông qua quy trình biên tập toàn diện. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Vượt qua những Thách thức của Kafka Connect với Amazon Data Firehose Tác giả: Swapna Bandla và Austin Groeneveld — 07 tháng 7, 2025 | trong Amazon Data Firehose, Amazon Kinesis, Amazon Managed Streaming for Apache Kafka (Amazon MSK), Phân tích dữ liệu, Trung cấp(200) Apache Kafka là một nền tảng phân phối luồng (streaming) mã nguồn mở phổ biến, được sử dụng rộng rãi trong hệ sinh thái AWS. Nó được thiết kế để xử lý các luồng dữ liệu thời gian thực với lưu lượng lớn, khiến nó rất phù hợp để xây dựng các đường ống dữ liệu thời gian thực nhằm đáp ứng nhu cầu streaming của các ứng dụng dựa trên đám mây hiện đại.\nĐối với những khách hàng AWS muốn chạy Apache Kafka nhưng không muốn lo lắng về những công việc nặng nhọc không tạo ra sự khác biệt liên quan đến việc tự quản lý các cụm Kafka của họ, Amazon Managed Streaming for Apache Kafka (Amazon MSK) cung cấp Apache Kafka được quản lý hoàn toàn. Điều này có nghĩa là Amazon MSK sẽ cấp phát máy chủ của bạn, cấu hình các cụm Kafka, thay thế máy chủ khi chúng bị lỗi, điều phối các bản vá và nâng cấp máy chủ, đảm bảo các cụm được kiến trúc để có tính sẵn sàng cao, đảm bảo dữ liệu được lưu trữ bền vững và bảo mật, thiết lập giám sát và cảnh báo, cũng như chạy mở rộng quy mô để hỗ trợ thay đổi tải. Với một dịch vụ được quản lý, bạn có thể dành thời gian của mình để phát triển và chạy các ứng dụng sự kiện streaming.\nĐể các ứng dụng sử dụng dữ liệu được gửi đến Kafka, bạn cần viết, triển khai và quản lý mã ứng dụng tiêu thụ dữ liệu từ Kafka.\nKafka Connect là một thành phần mã nguồn mở của dự án Kafka, cung cấp một khuôn khổ (framework) để kết nối với các hệ thống bên ngoài như cơ sở dữ liệu, kho lưu trữ key-value, chỉ mục tìm kiếm và hệ thống tệp từ các cụm Kafka của bạn. Trên AWS, khách hàng của chúng tôi thường viết và quản lý các connector (trình kết nối) sử dụng framework Kafka Connect để di chuyển dữ liệu ra khỏi cụm Kafka của họ vào bộ lưu trữ bền vững, như Amazon Simple Storage Service (Amazon S3), để lưu trữ dài hạn và phân tích lịch sử.\nỞ quy mô lớn, khách hàng cần quản lý cơ sở hạ tầng Kafka Connect theo lập trình để triển khai nhất quán khi cần cập nhật, cũng như mã xử lý lỗi, thử lại, nén hoặc chuyển đổi dữ liệu khi nó được chuyển từ cụm Kafka của bạn. Tuy nhiên, điều này nảy sinh nhu cầu đầu tư vào vòng đời phát triển phần mềm (SDLC) của phần mềm quản lý này. Mặc dù SDLC là một quy trình hiệu quả về chi phí và thời gian để giúp các nhóm phát triển xây dựng phần mềm chất lượng cao, nhưng đối với nhiều khách hàng, quy trình này không mong muốn cho trường hợp sử dụng phân phối dữ liệu của họ, đặc biệt là khi họ có thể dành nhiều nguồn lực hơn cho việc đổi mới các yếu tố khác biệt kinh doanh chính khác. Ngoài những thách thức về SDLC, nhiều khách hàng phải đối mặt với lưu lượng streaming dữ liệu dao động. Ví dụ:\nCác doanh nghiệp game trực tuyến trải qua sự thay đổi lưu lượng dựa trên việc sử dụng trò chơi Các ứng dụng phát trực tuyến video thấy sự thay đổi về lưu lượng tùy thuộc vào lượng người xem Các doanh nghiệp truyền thống có biến động lưu lượng gắn liền với hoạt động của người tiêu dùng Việc đạt được sự cân bằng phù hợp giữa tài nguyên và khối lượng công việc có thể là một thách thức. Cấp phát thiếu (under-provisioning) có thể dẫn đến độ trễ tiêu thụ (consumer lag), chậm trễ xử lý và khả năng mất dữ liệu trong thời gian tải cao điểm, cản trở các luồng dữ liệu thời gian thực và hoạt động kinh doanh. Mặt khác, cấp phát thừa (over-provisioning) dẫn đến tài nguyên không được sử dụng hết và chi phí cao không cần thiết, làm cho việc thiết lập trở nên kém hiệu quả về mặt kinh tế đối với khách hàng. Ngay cả hành động mở rộng quy mô cơ sở hạ tầng của bạn cũng gây ra thêm sự chậm trễ vì tài nguyên cần được cấp phát và thu thập cho cụm Kafka Connect của bạn.\nNgay cả khi bạn có thể ước tính lưu lượng tổng hợp, việc dự đoán lưu lượng trên mỗi luồng riêng lẻ vẫn rất khó khăn. Kết quả là, để đạt được hoạt động trơn tru, bạn có thể phải dùng đến cách cấp phát thừa tài nguyên (CPU) Kafka Connect cho các luồng của mình. Cách tiếp cận này, mặc dù hoạt động được, nhưng có thể không phải là giải pháp hiệu quả nhất hoặc tối ưu chi phí nhất.\nKhách hàng đã yêu cầu một giải pháp hoàn toàn serverless (không máy chủ) không chỉ xử lý việc quản lý phân bổ tài nguyên mà còn chuyển đổi mô hình chi phí sang việc chỉ trả tiền cho dữ liệu họ phân phối từ topic Kafka, thay vì các tài nguyên cơ bản đòi hỏi sự giám sát và quản lý liên tục.\nVào tháng 9 năm 2023, chúng tôi đã công bố một tích hợp mới giữa Amazon MSK và Amazon Data Firehose, cho phép các nhà xây dựng phân phối dữ liệu từ các topic MSK của họ đến các đích đến (sink) với một giải pháp serverless được quản lý hoàn toàn. Với tích hợp mới này, bạn không còn cần phải phát triển và quản lý mã của riêng mình để đọc, chuyển đổi và ghi dữ liệu vào đích bằng Kafka Connect nữa. Firehose trừu tượng hóa logic thử lại (retry logic) cần thiết khi đọc dữ liệu từ cụm MSK của bạn và phân phối nó đến đích mong muốn, cũng như việc cấp phát cơ sở hạ tầng, bởi vì nó có thể tự động mở rộng ra (scale out) và thu vào (scale in) để điều chỉnh theo khối lượng dữ liệu cần chuyển. Không yêu cầu hoạt động cấp phát hoặc bảo trì nào từ phía bạn.\nTại thời điểm phát hành, thời gian checkpoint để bắt đầu tiêu thụ dữ liệu từ topic MSK là thời gian tạo luồng Firehose. Firehose không thể bắt đầu đọc từ các điểm khác trên luồng dữ liệu. Điều này đã gây ra thách thức cho một số trường hợp sử dụng khác nhau.\nĐối với những khách hàng đang thiết lập cơ chế để đẩy dữ liệu từ cụm của họ lần đầu tiên, tất cả dữ liệu trong topic cũ hơn mốc thời gian tạo luồng Firehose sẽ cần một cách khác để được lưu trữ bền vững. Ví dụ, những khách hàng sử dụng các connector của Kafka Connect, những người dùng này bị hạn chế trong việc sử dụng Firehose vì họ muốn đẩy tất cả dữ liệu từ topic đến đích, nhưng Firehose không thể đọc dữ liệu từ trước mốc thời gian tạo luồng Firehose.\nĐối với những khách hàng khác đang chạy Kafka Connect và cần di chuyển từ cơ sở hạ tầng Kafka Connect của họ sang Firehose, điều này đòi hỏi một số sự phối hợp thêm. Chức năng khi phát hành của Firehose có nghĩa là bạn không thể trỏ luồng Firehose của mình đến một điểm cụ thể trên topic nguồn, vì vậy việc di chuyển đòi hỏi phải dừng nạp dữ liệu vào topic MSK nguồn và đợi Kafka Connect đẩy hết tất cả dữ liệu đến đích. Sau đó, bạn có thể tạo luồng Firehose và khởi động lại các producer (nhà sản xuất) sao cho luồng Firehose có thể tiêu thụ các tin nhắn mới từ topic. Điều này thêm chi phí bổ sung, và không hề nhỏ, vào nỗ lực di chuyển khi cố gắng chuyển đổi (cut over) từ cơ sở hạ tầng Kafka Connect hiện có sang một luồng Firehose mới.\nĐể giải quyết những thách thức này, chúng tôi vui mừng thông báo một tính năng mới trong tích hợp Firehose với Amazon MSK. Giờ đây, bạn có thể chỉ định luồng Firehose đọc từ vị trí sớm nhất trên topic Kafka hoặc từ một mốc thời gian tùy chỉnh để bắt đầu đọc từ topic MSK của bạn.\nTrong bài viết đầu tiên của loạt bài này, chúng tôi tập trung vào việc phân phối dữ liệu được quản lý từ Kafka đến hồ dữ liệu (data lake) của bạn. Trong bài viết này, chúng tôi mở rộng giải pháp để chọn một mốc thời gian tùy chỉnh cho topic MSK của bạn để được đồng bộ hóa với Amazon S3.\nTổng quan về tích hợp Firehose với Amazon MSK Firehose tích hợp với Amazon MSK để cung cấp một giải pháp được quản lý hoàn toàn giúp đơn giản hóa việc xử lý và phân phối dữ liệu streaming từ các cụm Kafka vào các hồ dữ liệu được lưu trữ trên Amazon S3. Chỉ với vài cú nhấp chuột, bạn có thể liên tục tải dữ liệu từ các cụm Kafka mong muốn của mình vào một bucket S3 trong cùng tài khoản, loại bỏ nhu cầu phát triển hoặc chạy các ứng dụng connector của riêng bạn. Sau đây là một số lợi ích chính của cách tiếp cận này:\nDịch vụ được quản lý hoàn toàn – Firehose là một dịch vụ được quản lý hoàn toàn, xử lý các tác vụ cấp phát, mở rộng quy mô và vận hành, cho phép bạn tập trung vào việc cấu hình đường ống phân phối dữ liệu. Cấu hình đơn giản hóa – Với Firehose, bạn có thể thiết lập đường ống phân phối dữ liệu từ Amazon MSK đến đích của mình chỉ với vài cú nhấp chuột trên AWS Management Console. Tự động mở rộng quy mô – Firehose tự động mở rộng quy mô để phù hợp với lưu lượng dữ liệu Amazon MSK của bạn mà không cần quản trị liên tục. Chuyển đổi và tối ưu hóa dữ liệu – Firehose cung cấp các tính năng như chuyển đổi JSON sang Parquet/ORC và tổng hợp theo lô (batch aggregation) để tối ưu hóa kích thước tệp được phân phối, đơn giản hóa các quy trình xử lý phân tích dữ liệu. Xử lý lỗi và thử lại – Firehose tự động thử lại việc phân phối dữ liệu trong trường hợp thất bại, với thời gian thử lại và các tùy chọn sao lưu có thể cấu hình. Tùy chọn chọn Offset – Với Firehose, bạn có thể chọn vị trí bắt đầu cho luồng phân phối MSK sẽ được phân phối trong một topic từ ba tùy chọn: - Thời gian tạo luồng Firehose – Tùy chọn này cho phép bạn phân phối dữ liệu bắt đầu từ thời gian tạo luồng Firehose. Khi di chuyển sang Firehose, nếu bạn có tùy chọn tạm dừng producer, bạn có thể xem xét tùy chọn này. - Sớm nhất (Earliest) – Tùy chọn này cho phép bạn phân phối dữ liệu bắt đầu từ thời gian tạo topic MSK. Bạn có thể chọn tùy chọn này nếu bạn đang thiết lập một đường ống phân phối mới với Firehose từ Amazon MSK đến Amazon S3. - Tại mốc thời gian (At timestamp) – Tùy chọn này cho phép bạn cung cấp ngày và giờ bắt đầu cụ thể trong topic từ nơi bạn muốn luồng Firehose đọc dữ liệu. Thời gian được tính theo múi giờ địa phương của bạn. Bạn có thể chọn tùy chọn này nếu bạn không muốn dừng các ứng dụng producer của mình trong khi di chuyển từ Kafka Connect sang Firehose. Bạn có thể tham khảo tập lệnh Python và các bước được cung cấp sau trong bài viết này để lấy mốc thời gian cho các sự kiện mới nhất trong topic của bạn đã được Kafka Connect tiêu thụ. Sau đây là những lợi ích của tính năng chọn mốc thời gian mới với Firehose:\nBạn có thể chọn vị trí bắt đầu của topic MSK, không chỉ từ thời điểm luồng Firehose được tạo, mà từ bất kỳ điểm nào từ mốc thời gian sớm nhất của topic. Bạn có thể phát lại (replay) việc phân phối luồng MSK nếu cần, ví dụ trong trường hợp các kịch bản kiểm thử để chọn từ các mốc thời gian khác nhau với tùy chọn chọn từ một mốc thời gian cụ thể. Khi di chuyển từ Kafka Connect sang Firehose, các khoảng trống hoặc bản ghi trùng lặp có thể được quản lý bằng cách chọn mốc thời gian bắt đầu cho việc phân phối Firehose từ điểm mà Kafka Connect kết thúc việc phân phối. Bởi vì tính năng mốc thời gian tùy chỉnh mới không giám sát offset của Kafka consumer trên mỗi phân vùng (partition), mốc thời gian bạn chọn cho topic Kafka của mình nên trước vài phút so với mốc thời gian bạn đã dừng Kafka Connect. Mốc thời gian bạn chọn càng sớm, bạn sẽ càng có nhiều bản ghi trùng lặp ở hạ nguồn. Mốc thời gian càng gần với thời gian dừng Kafka Connect, khả năng mất dữ liệu càng cao nếu một số phân vùng bị tụt lại phía sau. Hãy chắc chắn chọn một mốc thời gian phù hợp với yêu cầu của bạn. Tổng quan về Giải pháp Chúng tôi thảo luận về hai kịch bản để stream dữ liệu.\nTrong Kịch bản 1, chúng tôi di chuyển sang Firehose từ Kafka Connect với các bước sau: Lấy mốc thời gian mới nhất từ các sự kiện MSK mà Kafka Connect đã phân phối đến Amazon S3. Create a Firehose delivery stream với Amazon MSK là nguồn và Amazon S3 là đích với vị trí bắt đầu topic là Earliest (Sớm nhất). Truy vấn Amazon S3 để xác thực dữ liệu đã tải. Trong Kịch bản 2, chúng tôi tạo một đường ống dữ liệu mới từ Amazon MSK đến Amazon S3 với Firehose: Tạo một luồng phân phối Firehose với Amazon MSK là nguồn và Amazon S3 là đích với vị trí bắt đầu topic là At timestamp (Tại mốc thời gian). Truy vấn Amazon S3 để xác thực dữ liệu đã tải. Kiến trúc giải pháp được mô tả trong sơ đồ sau. Điều kiện tiên quyết Bạn nên có các điều kiện tiên quyết sau:\nMột tài khoản AWS và quyền truy cập vào các dịch vụ AWS sau: - Amazon Elastic Compute Cloud (Amazon EC2) - Amazon Data Firehose - AWS Identity and Access Management (IAM) - Amazon MSK - Amazon S3 Một cụm MSK được cấp phát hoặc MSK serverless với các topic đã được tạo và dữ liệu đang stream đến đó. Topic mẫu được sử dụng trong bài này là order. Một instance EC2 được cấu hình để sử dụng làm Kafka admin client. Tham khảo Tạo vai trò IAM để biết hướng dẫn tạo máy khách và vai trò IAM mà bạn sẽ cần để chạy các lệnh đối với cụm MSK của mình. Một bucket S3 để phân phối dữ liệu từ Amazon MSK sử dụng Firehose. Kafka Connect để phân phối dữ liệu từ Amazon MSK đến Amazon S3 nếu bạn muốn di chuyển từ Kafka Connect (Kịch bản 1). Migrate to Firehose from Kafka Connect Để giảm trùng lặp và giảm thiểu mất dữ liệu, bạn cần cấu hình timestamp tùy chỉnh để Firehose đọc dữ liệu gần với timestamp của offset được Kafka Connect commit sớm nhất. Bạn có thể làm theo các bước trong phần này để hình dung cách timestamp của mỗi offset được commit sẽ thay đổi tùy theo từng partition của topic bạn muốn đọc. Đây chỉ là ví dụ minh họa và không thể mở rộng cho workload có số lượng partition lớn.\nDữ liệu mẫu được tạo theo hướng dẫn trong GitHub repo này. Chúng tôi thiết lập một ứng dụng producer mẫu để tạo các sự kiện clickstream mô phỏng người dùng duyệt web và thực hiện thao tác trên một trang thương mại điện tử giả lập.\nĐể lấy timestamp mới nhất từ các sự kiện MSK mà Kafka Connect gửi vào Amazon S3, hãy thực hiện các bước sau:\nTừ Kafka client của bạn, truy vấn Amazon MSK để lấy Kafka Connect consumer group ID: ./kafka-consumer-groups.sh --bootstrap-server $bs --list --command-config client.properties Dừng Kafka Connect.\nTruy vấn Amazon MSK để lấy offset mới nhất và timestamp tương ứng của consumer group thuộc Kafka Connect.\nBạn có thể sử dụng script Python get_latest_offsets.py trong GitHub repo để tham khảo cách lấy timestamp tương ứng với các offset mới nhất của Kafka Connect consumer group.\nĐể bật xác thực và phân quyền cho client không sử dụng Java trong MSK được cấu hình IAM, hãy tham khảo hướng dẫn cài đặt package aws-msk-iam-sasl-signer-python trong repo sau để xem hướng dẫn cài đặt package aws-msk-iam-sasl-signer-python cho client của bạn.\npython3 get_latest_offsets.py --broker-list $bs --topic-name “order” --consumer-group-id “connect-msk-serverless-connector-090224” --aws-region “eu-west-1” Hãy ghi lại timestamp sớm nhất trong tất cả các partition.\nCreate a data pipeline from Amazon MSK to Amazon S3 with Firehose Các bước trong phần này áp dụng cho cả hai kịch bản. Hãy thực hiện các bước sau để tạo data pipeline của bạn:\nTrên giao diện Firehose console, chọn Firehose streams trong thanh điều hướng. Chọn Create Firehose stream. Ở mục Source, chọn Amazon MSK. Ở mục Destination, chọn Amazon S3 Trong phần Source settings, duyệt đến MSK cluster và nhập tên topic mà bạn đã tạo trong bước chuẩn bị. Cấu hình vị trí bắt đầu (starting position) của Firehose stream dựa trên kịch bản của bạn: For Scenario 1, set Topic starting position as At Timestamp and enter the timestamp you noted in the previous section. For Scenario 2, set Topic starting position as Earliest. Đối với Firehose stream name, giữ nguyên tên mặc định được tạo hoặc nhập tên bạn muốn. Trong phần Destination settings, duyệt đến S3 bucket đã được tạo trong bước chuẩn bị để stream dữ liệu. Bên trong S3 bucket này, theo mặc định, một cấu trúc thư mục theo dạng YYYY/MM/dd/HH sẽ được tự động tạo ra. Dữ liệu sẽ được gửi vào các thư mục con tương ứng với thư mục HH dựa trên timestamp mà Firehose ghi nhận khi đưa dữ liệu vào Amazon S3.\nTrong phần Advanced settings, bạn có thể chọn tạo IAM role mặc định với đầy đủ quyền mà Firehose cần, hoặc chọn một IAM role hiện có đã được gán các policy phù hợp cho Firehose. Chọn Create Firehose stream. Trên giao diện Amazon S3 console, bạn có thể kiểm tra dữ liệu đã được stream vào thư mục S3 theo đúng cấu hình offset mà bạn đã chọn.\nClean up Để tránh phát sinh chi phí trong tương lai, hãy xóa các tài nguyên bạn đã tạo trong bài thực hành này nếu bạn không có kế hoạch sử dụng chúng thêm.\nConclusion Firehose cung cấp một cách đơn giản để truyền dữ liệu từ Amazon MSK đến Amazon S3, giúp bạn tiết kiệm chi phí và giảm độ trễ xuống chỉ còn vài giây.\nĐể trải nghiệm Firehose với Amazon S3, hãy tham khảo bài lab Delivery to Amazon S3 using Amazon Data Firehose.\nAbout the Authors Aditya Shahani Aditya Shahani là một Startup Solutions Architect tập trung vào việc hỗ trợ và tăng tốc các startup giai đoạn đầu trong hành trình xây dựng trên AWS. Anh đam mê việc tận dụng các công nghệ mới nhất để tối ưu hóa và giải quyết các vấn đề kinh doanh ở quy mô lớn. Bonnie McClure Bonnie là một biên tập viên chuyên tạo ra nội dung dễ tiếp cận và hấp dẫn cho mọi đối tượng và nền tảng. Cô luôn tận tâm cung cấp định hướng biên tập toàn diện nhằm mang lại trải nghiệm người dùng liền mạch và nhất quán. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Cách Brisa Robotics Sử Dụng AWS để Cải Thiện Hoạt Động Robotics bởi Erica Goldberger và Sophie Pagalday vào ngày 24 THÁNG 02, 2023 trong Amazon Kinesis, Amazon Simple Storage Service (S3), Amazon Timestream, Analytics, AWS IoT Greengrass, AWS Lambda, Customer Solutions, Database, Internet of Things, Kinesis Data Analytics, Robotics, Storage, Technical How-to | Permalink | Share\nTrong bài viết này, bạn sẽ tìm hiểu cách Brisa Robotics tận dụng Amazon Web Services (AWS) để thu thập, lưu trữ và xử lý dữ liệu từ các đội phương tiện hỗn hợp nhằm cải thiện hoạt động của khách hàng.\nBrisa chuyển đổi các máy móc không tự động thành các đội xe tự động có khả năng thu thập dữ liệu, giúp khách hàng theo dõi các chỉ số hiệu suất quan trọng và cải thiện vận hành. Sứ mệnh của họ là nâng cao hiệu quả vận hành cho khách hàng bằng cách tận dụng cơ sở hạ tầng hiện có và tái sử dụng các máy cũ thay vì bán phế liệu và mua mới. Brisa cung cấp các bộ kit robot mô-đun độc đáo để nâng cấp thiết bị xử lý vật liệu (MHE) như xe nâng, palletizer và telehandler. Các bộ kit này được lắp bổ sung vào MHE để tích hợp nền tảng thu thập dữ liệu độc quyền của Brisa. Chúng hỗ trợ nhiều trường hợp sử dụng như: theo dõi SKU, kiểm tra (lỗi, vật thể, mã vạch), và di chuyển vật liệu. Khả năng quan sát tốt hơn vào những trường hợp sử dụng này thông qua dữ liệu và chỉ số giúp khách hàng Brisa tối ưu hóa bố cục kho và lập kế hoạch tốt hơn.\nChallenge: Build a Flexible Data Collection Solution Tập đoàn sản xuất bia lớn nhất thế giới cần khả năng quan sát tốt hơn đối với hoạt động kho và hàng tồn để tăng năng suất và cải thiện an toàn. Vì vậy Brisa bắt tay vào xây dựng một giải pháp để thu thập và truyền dữ liệu nhằm giúp khách hàng đưa ra quyết định tốt hơn.\nBrisa cam kết không thay đổi cơ sở hạ tầng của khách hàng nhằm tránh tăng chi phí vận hành và bảo trì cho họ. Họ muốn hỗ trợ khách hàng mà không yêu cầu thay đổi bất kỳ hệ thống hiện có nào. Bên cạnh đó, Brisa cần cung cấp một giải pháp duy nhất có thể hoạt động với các khách hàng có quy trình và yêu cầu khác nhau.\nTùy thuộc vào khách hàng, Brisa phải xem xét nhiều yêu cầu khác nhau. Ví dụ, một số khách hàng muốn bảng điều khiển dữ liệu chỉ khả dụng trong mạng nội bộ của họ, trong khi những khách hàng khác muốn bảng điều khiển trực tuyến. Thêm vào đó, có khách hàng muốn sử dụng một máy tính cục bộ để thu thập dữ liệu trước khi gửi lên đám mây, trong khi những khách hàng khác muốn dữ liệu được gửi thẳng từ robot. Brisa cần một công cụ linh hoạt có thể chạy trên nhiều nền tảng cho các kịch bản khác nhau.\nMục tiêu là phát triển một giải pháp linh hoạt để thu thập và cung cấp dữ liệu và chỉ số cho các khách hàng đa dạng mà không yêu cầu họ phải thay đổi bất kỳ cơ sở hạ tầng nào.\nSolution Overview Brisa đã phát triển một giải pháp thu thập dữ liệu từ các robot MHE; truyền, xử lý và lưu trữ dữ liệu trên AWS; đồng thời đưa dữ liệu vào các dashboard tùy chỉnh theo thời gian thực cho khách hàng. Toàn bộ quy trình này diễn ra mà không cần thay đổi cơ sở hạ tầng của khách hàng, và workflow vẫn có thể hoạt động dù kết nối internet không ổn định hoặc bị gián đoạn.\nCác thành phần của AWS IoT Greengrass V2 được triển khai lên các robot, bao gồm cả các thành phần dựng sẵn như stream manager. Dữ liệu được thu thập từ ứng dụng client chạy trên server (có thể là robot hoặc một máy khác trong mạng của robot). Ứng dụng này có thể chạy như một custom Greengrass component hoặc chạy độc lập ngoài Greengrass. Thành phần stream manager sẽ stream dữ liệu trực tiếp đến Amazon Kinesis Data Streams (Amazon KDS) và Amazon Simple Storage Service (Amazon S3). Một hàm AWS Lambda viết bằng Python sẽ xử lý dữ liệu thô từ Kinesis Data Stream và lưu dữ liệu vào cơ sở dữ liệu Amazon Timestream. Khi dữ liệu đã nằm trong AWS, ứng dụng web của Brisa có thể truy vấn Amazon Timestream để lấy dữ liệu hiển thị trên dashboard. Bạn sẽ tìm hiểu chi tiết hơn về workflow này ở phần dưới.\nCollecting the Data Brisa thu thập dữ liệu trên robot, bao gồm phát hiện vật thể, vị trí robot, tốc độ robot, chuyển động của càng nâng, và giám sát hệ thống. Họ thực hiện điều này bằng cách sử dụng Robot Operating System 2 (ROS2), một bộ thư viện và công cụ mã nguồn mở dùng để xây dựng ứng dụng robot. ROS2 giúp Brisa phát triển và triển khai ứng dụng robot nhanh hơn nhờ sử dụng các node và công cụ được cộng đồng xây dựng, như mô phỏng và build tooling. Là thành viên sáng lập của ủy ban chỉ đạo kỹ thuật ROS2, AWS đóng vai trò quan trọng trong cộng đồng, cung cấp nhiều tùy chọn phong phú để vận hành các công cụ ROS2 trên AWS. AWS mang đến cho Brisa nền tảng đám mây có khả năng mở rộng cao nhất cùng các tích hợp sâu nhất với ROS2.\nStreaming the Data Brisa đăng ký (subscribe) vào topic ROS2 và chuyển tiếp các sự kiện đó vào Kinesis data stream bằng cách sử dụng AWS IoT Greengrass V2 stream manager. AWS IoT Greengrass là một edge runtime và dịch vụ đám mây mã nguồn mở dành cho Internet of Things (IoT), giúp bạn xây dựng, triển khai và quản lý các ứng dụng IoT trên thiết bị. Bạn có thể sử dụng AWS IoT Greengrass để xây dựng ứng dụng edge bằng các module phần mềm dựng sẵn hoặc tùy chỉnh, gọi là components, có thể kết nối thiết bị edge của bạn với các dịch vụ AWS hoặc dịch vụ của bên thứ ba. Thành phần stream manager cho phép bạn xử lý các luồng dữ liệu để truyền về AWS Cloud từ các thiết bị Greengrass core.\nBrisa chọn Greengrass stream manager vì nó có thể hoạt động offline khi mạng không ổn định, mà không cần phải lo lắng về việc buffer hay gửi dữ liệu lên AWS. Dữ liệu được lưu trữ cục bộ và nén lại cho đến khi có kết nối internet. Thay vì phải tự quản lý workflow này, Brisa chỉ cần gửi dữ liệu vào stream và tập trung vào các quy trình robot của riêng họ. Cách triển khai này linh hoạt cho nhiều nhu cầu khách hàng, vì Greengrass stream manager có thể chạy trực tiếp trên các robot hoặc trên máy tính cục bộ mà robot gửi dữ liệu đến.\nBrisa có một ứng dụng client đang chạy và một server để khởi động stream manager. Tùy vào khách hàng, server này có thể nằm trên robot hoặc trên một máy khác trong mạng của robot. Để biết thêm thông tin về việc thiết lập stream manager, hãy xem tài liệu stream manager và bài viết Deploy and Manage ROS Robots with AWS IoT Greengrass V2.\nSau đó, Brisa sử dụng một ROS2 node để thu thập dữ liệu từ các cảm biến. Họ thực hiện điều này bằng cách tạo một ROS2 package.\nSample commands to create a new ROS2 package:.\nSample commands to create a new ROS2 package: cd ~ mkdir -p ws/src pip install stream_manager cd src ros2 pkg create \\ --package-format 3 \\ --build-type ament_python \\ sm_upload Brisa đưa dữ liệu lên Kinesis data stream và Amazon S3 bucket thông qua Greengrass stream manager. Họ thực hiện điều này bằng cách sử dụng Python SDK của stream manager trong các ROS node của mình. Dưới đây là một ví dụ ROS node tương tự cách Brisa triển khai, dùng để publish dữ liệu từ ROS lên stream manager:\nimport json import rclpy from rclpy.node import Node from stream_manager import ( ExportDefinition, KinesisConfig, MessageStreamDefinition, StrategyOnFull, StreamManagerClient, ) STREAM_NAME = \u0026#34;SomeStream\u0026#34; KINESIS_STREAM_NAME = \u0026#34;MyKinesisStream\u0026#34; class StreamManagerPublisher(Node): def __init__(self): super().__init__(\u0026#34;aws_iot_core_publisher\u0026#34;) timer_period = 3 # seconds self.client = StreamManagerClient() exports = ExportDefinition( kinesis=[ KinesisConfig( identifier=\u0026#34;KinesisExport\u0026#34; + STREAM_NAME, kinesis_stream_name=KINESIS_STREAM_NAME, ) ] ) # Create the Status Stream if it does not exist already try: self.client.create_message_stream( MessageStreamDefinition( name=STREAM_NAME, strategy_on_full=StrategyOnFull.OverwriteOldestData, export_definition=exports, ) ) except ConnectionRefusedError as e: self.get_logger().error(f\u0026#34;Could not connect to the stream manager: {str(e)}\u0026#34;) raise except Exception: pass # Create the message stream with the S3 Export definition. self.client.create_message_stream( MessageStreamDefinition( name=STREAM_NAME, strategy_on_full=StrategyOnFull.OverwriteOldestData, export_definition=exports, ) ) self.timer = self.create_timer(timer_period, self.timer_callback) def timer_callback(self): self.client.append_message(STREAM_NAME, json.dumps({\u0026#34;robot_id\u0026#34;: \u0026#34;C3PO\u0026#34;,\u0026#34;timestamp\u0026#34;: datetime.datetime.utcnow().isoformat(),\u0026#34;x\u0026#34;: 1.0, \u0026#34;y\u0026#34;: 1.1, \u0026#34;z\u0026#34;: 3.0}).encode(\u0026#34;utf-8\u0026#34;)) self.get_logger().info(\u0026#34;Successfully appended S3 Task Definition to stream\u0026#34;) def main(args=None): rclpy.init(args=args) sm_publisher = StreamManagerPublisher() rclpy.spin(sm_publisher) sm_publisher.destroy_node() rclpy.shutdown() if __name__ == \u0026#34;__main__\u0026#34;: main() Sau đó, họ tiến hành build ROS2 package:\ncolcon build --packages-up-to sm_upload source install/setup.bash ros2 run sm_upload sm_upload Storing the Data Brisa sử dụng stream manager để truyền một phần dữ liệu, như hình ảnh và video, vào Amazon S3 để lưu trữ đối tượng. Phần dữ liệu còn lại, chẳng hạn dữ liệu telemetry, được truyền vào Amazon Kinesis Data Streams, xử lý bằng AWS Lambda, và sau đó lưu vào Amazon Timestream — một cơ sở dữ liệu được xây dựng chuyên biệt cho dữ liệu chuỗi thời gian (time-series).\nAmazon Kinesis Data Streams giúp thu nhận và gom dữ liệu từ ứng dụng và log dịch vụ, đồng thời đưa dữ liệu vào data lake. Xem Create a data stream để tìm hiểu thêm về cách tạo một stream.\nBrisa sử dụng một hàm AWS Lambda để điều phối các bước extract, process và load (ETL) từ Amazon Kinesis vào Amazon Timestream. Họ chọn Lambda vì đây là dịch vụ serverless, nghĩa là chi phí phụ thuộc vào số lượng request và thời gian chạy của hàm (thời gian thực thi code). Họ đã xem xét các tùy chọn ETL được quản lý khác trong AWS nhưng nhận thấy sử dụng Lambda đơn giản là phù hợp nhất cho yêu cầu ETL hiện tại.\nQuerying Newly Stored Data for Their Dashboards Khi dữ liệu đã nằm trong Timestream, Brisa có thể sử dụng các time series functions để thực hiện những truy vấn đơn giản nhưng hiệu quả nhằm hiển thị các chỉ số dựa trên thời gian. Từ giao diện Amazon Timestream console, Brisa có thể kiểm thử các truy vấn dạng SQL. Để tìm hiểu chi tiết hơn, hãy xem Timestream Concepts và Using the console.\nDưới đây là một ví dụ truy vấn mà Brisa có thể chạy để trích xuất dữ liệu kinh doanh hữu ích. Trong truy vấn này, vị trí (positions) được nhóm theo từng khoảng 5 giây để lấy giá trị trung bình của tọa độ x và y. Điều này giúp tối ưu chi phí truy vấn bằng cách không phải lấy toàn bộ dữ liệu mọi lúc.\nSELECT ROUND(AVG(x), 2) AS avg_x, ROUND(AVG(y), 2) AS avg_y, BIN(time, 5s) AS binned_timestamp FROM database.table WHERE x IS NOT NULL AND y IS NOT NULL AND robot_name=\u0026#34;C3PO\u0026#34; GROUP BY BIN(time, 5s) ORDER BY binned_timestamp ASC Brisa cũng có thể truy vấn dữ liệu đã thu thập bằng nhiều SDK khác nhau như boto3 cho Python hoặc AWSJavascriptSDK cho JavaScript. Danh sách đầy đủ các ngôn ngữ lập trình được hỗ trợ có thể xem tại Tools to Build on AWS.\nBrisa sau đó sử dụng các truy vấn này để lấy dữ liệu liên quan đưa vào dashboard dành cho khách hàng.\nBrisa thực hiện truy vấn Timestream từ backend bằng AWS SDK for pandas (trước đây là AWS Data Wrangler) để lấy và xử lý dữ liệu phục vụ dashboard và API. Phần frontend sẽ hiển thị dữ liệu này lên dashboard.\nResults Khi dữ liệu đã nằm trong AWS, Brisa có thể dễ dàng truy vấn thông tin đã thu thập, xử lý và cung cấp chúng dưới dạng dashboard trực tiếp và báo cáo KPI cho khách hàng. Thư viện chỉ số và trực quan hóa của Brisa mang tính mô-đun và động, liên tục được cập nhật để đáp ứng tích hợp và trường hợp sử dụng mới theo nhu cầu khách hàng. Khả năng này giúp khách hàng cải thiện mức độ an toàn tổng thể và hiệu quả trong kho của họ.\nTrước khi có giải pháp của Brisa, công ty sản xuất bia hầu như xử lý việc theo dõi hoàn toàn thủ công. Nhờ vào dashboard và báo cáo, Brisa hiện có thể mang đến cho họ:\nĐộ chính xác cao hơn: Các thùng chai được lưu trữ cách mặt đất khoảng 5 mét, rất khó để một người quan sát và nhận diện chính xác. Giải pháp của Brisa thu thập hình ảnh từ camera giúp xác định chính xác các thùng chai. Tần suất dữ liệu cao hơn: Robot tự động có thể quét dữ liệu với tần suất gấp đôi so với con người làm thủ công. Cải thiện an toàn: Xe nâng thường di chuyển trong cùng lối đi với người kiểm kho, gây nguy hiểm. Việc giao cho robot đảm nhận nhiệm vụ này giúp loại bỏ nguy cơ tai nạn giữa xe nâng và nhân viên. Thông tin vận hành tốt hơn: Các heatmap trong dashboard thời gian thực giúp khách hàng của Brisa phát hiện các điểm nghẽn trong hoạt động và tối ưu lịch làm việc. Loại insight này không thể có được chỉ bằng quan sát thủ công. Dưới đây là một số ảnh chụp màn hình từ dashboard của Brisa:\nHeatmap vị trí trong khu vực kiểm thử nội bộ của Brisa. Lý tưởng nhất là không nên có khu vực nào robot phải dừng lại, nhưng khi quan sát heatmap này, bạn có thể thấy một số khu vực nơi robot dừng lại thường xuyên hơn những nơi khác. Điều này có thể xuất phát từ nhiều nguyên nhân: tuyến đường robot không tối ưu, biển báo kém, kế hoạch di chuyển chưa tốt, hoặc các vấn đề nghiêm trọng hơn như có người hoặc robot khác chặn lối. Để giải quyết điều này, Brisa cũng thu thập hình ảnh từ camera để khách hàng có thể xem lại chuyện gì đã xảy ra. Những hình ảnh này giúp công ty sản xuất bia hiểu cách cải thiện bố cục kho hoặc điều chỉnh kế hoạch sao cho robot di chuyển mượt mà, không bị gián đoạn trong quá trình vận hành.\nDashboard với hình ảnh camera và góc nhìn của robot. Dashboard này lấy các tệp này từ Amazon S3, nơi dữ liệu được stream manager lưu trữ.\nDashboard hiển thị hình ảnh từ khu vực vận hành của khách hàng.\nDashboard hiển thị một số chỉ số mà Brisa cung cấp cho khách hàng. Tất cả các chỉ số này đều được truy vấn từ Timestream. Bên cạnh các chỉ số tiêu chuẩn (như thời gian hoạt động và quãng đường di chuyển), thiết kế mô-đun sử dụng AWS giúp Brisa dễ dàng cung cấp các tích hợp tùy chỉnh cho khách hàng, chẳng hạn như:\nSố lần phương tiện dừng lại: Đây là chỉ số được công ty sản xuất bia sử dụng nội bộ. Dashboard cho biết mỗi lần dừng diễn ra trong bao lâu. Khách hàng có thể nhấp vào kết quả để xem các sự kiện liên quan xảy ra vào thời điểm đó. Ví dụ, với một lần dừng, họ có thể thấy một hình ảnh phát hiện có người xuất hiện. Người dùng có thể nhấp vào ảnh để xem vị trí trong kho nơi sự kiện này xảy ra và thời điểm cụ thể. Điều này giúp khách hàng hiểu rõ xu hướng dừng của robot theo thời gian để cải thiện hiệu quả vận hành.\nTổng quan tải trọng (Load summary): Robot nên di chuyển phần lớn thời gian, ngoại trừ thời gian sạc hoặc một số thời điểm dừng ngắn.\nBrisa tùy chỉnh dashboard dựa trên từng đội robot, loại robot được sử dụng và các KPI quan trọng đối với từng khách hàng.\nVới pipeline streaming dữ liệu này, Brisa có thể cung cấp cho khách hàng công cụ để theo dõi hàng hóa và hiểu sâu hơn về các vấn đề vận hành mà không cần thay đổi workflow của họ. Khả năng này giúp các khách hàng, chẳng hạn như công ty sản xuất bia, cải thiện hiệu quả vận hành và an toàn trong kho.\nBrisa đang tích hợp với nhiều khách hàng và nhiều loại robot hơn, liên tục bổ sung các chỉ số chuyên sâu và tùy chỉnh vào dashboard của họ.\nBrisa có thể giúp bạn kiểm soát hàng hóa thường xuyên và chính xác hơn, xác định và giải quyết các điểm nghẽn trong vận hành (thủ công và/hoặc tự động), và đưa ra quyết định dựa trên dữ liệu thực tế. Để tìm hiểu thêm, hãy truy cập website www.brisa.tech.\nTAGS: autonomous robots, AWS Robotics, Cloud Robotics\nAbout the Authors Aditya Shahani Aditya Shahani là Startup Solutions Architect tập trung hỗ trợ các startup giai đoạn đầu tăng tốc trong hành trình xây dựng trên AWS. Anh đam mê việc tận dụng các công nghệ mới nhất để tối ưu hóa và đơn giản hóa các bài toán kinh doanh ở quy mô lớn. Bonnie McClure Bonnie là một biên tập viên chuyên tạo nội dung dễ tiếp cận và hấp dẫn cho mọi đối tượng và nền tảng. Cô luôn tận tâm mang đến định hướng biên tập toàn diện nhằm đem lại trải nghiệm người dùng liền mạch. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"TaskHub - Nền tảng quản lý nhiệm vụ và tiến độ theo mô hình DevSecOps trên AWS 1. Tóm tắt điều hành TaskHub là nền tảng quản lý nhiệm vụ và tiến trình được thiết kế nhằm giúp các nhóm làm việc hoặc doanh nghiệp vừa và nhỏ có thể quản lý công việc, thời hạn và tiến trình một cách trực quan và an toàn.\nHệ thống được phát triển theo mô hình DevSecOps, phát triển hoàn toàn trên AWS Serverless, đảm bảo khả năng mở rộng, bảo mật và tối ưu chi phí.\nQuy trình phát triển khai báo sử dụng AWS CodePipeline và CodeBuild để tự động hóa CI/CD và kiểm tra bảo mật.\n2. Phát biểu vấn đề Vấn đề:\nDoanh nghiệp nhỏ và các nhóm dự án thường gặp khó khăn trong việc quản lý khối lượng công việc, theo dõi tiến độ và phân phối giữa các thành viên.\nCác công cụ quản lý phổ biến như Jira hoặc Asana thường có chi phí cao và không được hỗ trợ liền mạch với quy trình DevSecOps hoặc môi trường AWS.\nGiải pháp:\nTaskHub sử dụng kiến trúc Serverless trên AWS để xây dựng nền tảng nhẹ nhàng, bảo mật và tiết kiệm chi phí.\nNền tảng được phát triển bằng AWS Lambda, API Gateway, DynamoDB, Cognito và S3/CloudFront, đồng thời tích hợp AWS CodePipeline cho CI/CD và kiểm tra bảo mật động.\nLợi ích và lợi tức đầu tư\nGiải pháp TaskHub mang lại nhiều lợi ích thiết thực cho các nhóm phát triển và doanh nghiệp vừa và nhỏ. Hệ thống đóng vai trò là một nền tảng trung tâm giúp quản lý nhiệm vụ, theo dõi tiến trình và phân quyền thành viên một cách hiệu quả. Việc ứng dụng mô hình serverless trên AWS giúp giảm thiểu chi phí vận hành, tối ưu tài nguyên và tăng khả năng mở rộng khi nhu cầu sử dụng tăng cao. Bên cạnh đó, nền tảng này vẫn hỗ trợ xây dựng môi trường thực hành DevSecOps, tạo tiền đề cho các nhóm nghiên cứu và phát triển có thể mở rộng các dự án hơn nữa. Theo ước tính từ Máy tính giá AWS, chi phí vận hành hệ thống chỉ khoảng 0,66 USD mỗi tháng, tương đương 7,92 USD mỗi năm, trong khi toàn bộ tầng hạ tầng ban đầu tận dụng dịch vụ dùng chung từ AWS, không phát sinh phần cứng vật lý. Dự kiến thời gian hoàn vốn đạt được trong 6\u0026ndash;12 tháng nhờ giảm thiểu đáng kể công việc quản lý thủ công và tối ưu hóa quy trình làm việc nội bộ.\n3. Kiến trúc giải pháp Nền tảng TaskHub được xây dựng dựa trên kiến trúc AWS Serverless, đảm bảo khả năng mở rộng hoạt động, hiệu suất cao và nền tảng vận hành chi phí. Hệ thống tập trung vào công việc quản lý nhiệm vụ, công việc nhóm và dự án tiến độ theo thời gian thực, đồng thời duy trì quy trình phát triển khai tự động hóa thông tin qua mô hình DevSecOps.\nKiến trúc tổng thể bao gồm các thành phần chính như Amazon API Gateway đảm nhận trách nhiệm tiếp nhận và phân phối yêu cầu từ người dùng, AWS Lambda xử lý phần phụ trợ nghiệp vụ và tương tác với cơ sở dữ liệu Amazon DynamoDB để lưu trữ thông tin nhiệm vụ, người dùng và quyền truy cập.\nPhần giao diện web được lưu trữ thông tin qua Amazon S3 và phân phối toàn cầu bằng Amazon CloudFront, trong khi AWS Cognito đảm bảo độ xác thực và phân quyền cho người dùng.\nQuy trình CI/CD được tự động hóa bằng AWS CodePipeline kết hợp với AWS CodeBuild, giúp phát triển khai báo và kiểm tra bảo mật liên tục mà không cần quản lý máy chủ.\nToàn bộ kiến trúc được bảo vệ bởi AWS WAF và AWS KMS nhằm tăng cường bảo mật dữ liệu và đảm bảo bổ sung quy chuẩn DevSecOps. AWS X-Ray được sử dụng để theo dõi hiệu suất và phân tích độ trễ. Kiến trúc tổng hợp được mô tả chi tiết trong sơ đồ bên dưới:\nDịch vụ AWS đã sử dụng Amazon Route 53: Dịch vụ DNS đáng tin cậy cao, định tuyến traffic.\nAWS WAF (Web Application Firewall): Lớp bảo vệ nâng cao, chặn các cuộc tấn công phổ biến.\nAmazon CloudFront: Phân phối giao diện người dùng và nội dung tĩnh toàn cầu.\nAmazon S3 (Simple Storage Service): Lưu trữ tĩnh toàn bộ mã nguồn giao diện web (Next.js build files).\nAmazon Cognito: Quản lý xác thực và cấp quyền người dùng.\nAmazon API Gateway: Lớp giao tiếp trung gian, thực hiện xác thực và định tuyến các API yêu cầu đến Lambda.\nAWS Lambda: Xử lý nghiệp vụ chính. Được tích hợp để ghi nhật ký hoạt động vào CloudWatch Logs.\nAmazon DynamoDB: Cơ sở dữ liệu NoSQL hiệu suất cao. Dữ liệu được mã hóa bằng AWS KMS.\nAWS SNS (Simple Notification Service): Đảm nhận vai trò thông báo không đồng bộ.\nAWS Secrets Manager: Lưu trữ, quản lý và luân phiên các bí mật một cách an toàn.\nAWS CodePipeline, CodeBuild, \u0026amp; CodeGuru:\nCodePipeline/CodeBuild: Xây dựng và tự động hóa quy trình CI/CD. CodeBuild thực hiện các bài kiểm tra tự động và Quét Bảo mật Tĩnh (SAST).\nAWS CodeGuru: Công cụ phân tích mã nguồn tự động, được tích hợp vào quy trình CI/CD để đưa ra đề xuất thông minh về việc tối ưu hóa hiệu suất và cải thiện chất lượng mã, đặc biệt quan trọng trong môi trường Lambda.\nAWS CloudFormation: Dịch vụ Cơ sở hạ tầng dưới dạng Mã (IaC) để triển khai toàn bộ tài nguyên.\nAWS CloudWatch Logs \u0026amp; AWS X-Ray: CloudWatch Logs thu thập nhật ký. CloudWatch sử dụng dữ liệu này để thiết lập cảnh báo. AWS X-Ray cung cấp khả năng theo dõi truy vết (tracing) chuyên sâu.\nThiết kế Thành phần Lớp Người dùng giao diện (Frontend):\nGiao diện: Ứng dụng Next.js được build dưới dạng tĩnh (Static Build).\nLưu trữ \u0026amp; Phân phối: Các file tĩnh được lưu trữ an toàn trong Amazon S3 (được cấu hình là Origin cho CloudFront). Giao diện này được phân phối toàn cầu bằng Amazon CloudFront với độ trễ thấp, đồng thời được bảo vệ bởi AWS WAF (Web Application Firewall) tại lớp Edge.\nLớp Xử lý nghiệp vụ (Backend):\nCổng API: Amazon API Gateway tiếp nhận mọi yêu cầu. Nó được cấu hình với Cognito Authorizer để xác thực Token của người dùng trước khi chuyển tiếp yêu cầu.\nXử lý: Các Lambda Functions chịu trách nhiệm xử lý logic nghiệp vụ (CRUD nhiệm vụ, quản lý nhóm, phân quyền).\nQuản lý Bí mật: Mỗi Lambda function truy cập các thông tin nhạy cảm (như khóa API ngoài) thông qua AWS Secrets Manager, đảm bảo các bí mật không bao giờ được mã hóa cứng trong code.\nLớp Dữ liệu (Cơ sở dữ liệu):\nCơ sở dữ liệu: Amazon DynamoDB được sử dụng để lưu trữ dữ liệu nhiệm vụ, tiến độ và cấu hình người dùng. DynamoDB hoạt động ở chế độ On-Demand để tự động mở rộng và tối ưu chi phí.\nBảo mật Dữ liệu: Toàn bộ dữ liệu tại chỗ (at-rest) trong DynamoDB được mã hóa bằng khóa quản lý bởi AWS KMS (Key Management Service), đáp ứng tiêu chuẩn bảo mật cao nhất.\nBảo mật và Xác thực:\nXác thực: Amazon Cognito cung cấp cơ chế đăng nhập, quản lý phiên và phân quyền người dùng theo vai trò (Role-Based Access Control). Cognito cũng hỗ trợ Xác thực Đa Yếu tố (MFA) và tích hợp SSO (Single Sign-On).\nBảo vệ Edge: AWS WAF được đặt trước CloudFront để ngăn chặn các cuộc tấn công DDoS ở Lớp 7 (Layer 7) và các lỗi bảo mật phổ biến khác (OWASP Top 10).\nTriển khai và Giám sát:\nCI/CD DevSecOps: Mã nguồn được lưu trữ trên GitLab (theo sơ đồ) và được tự động hóa qua chuỗi AWS CodePipeline/CodeBuild. Quá trình này bao gồm việc chạy CodeGuru để tối ưu code trước khi triển khai hạ tầng qua CloudFormation.\nGiám sát \u0026amp; Gỡ lỗi: AWS CloudWatch Logs thu thập nhật ký chi tiết từ tất cả các dịch vụ. AWS CloudWatch sử dụng các nhật ký này để thiết lập cảnh báo tự động khi phát hiện lỗi hoặc sự cố. AWS X-Ray cung cấp cái nhìn tổng quan về hiệu suất luồng giao dịch, hỗ trợ gỡ lỗi và tối ưu độ trễ.\n4. Triển khai kỹ thuật Việc phát triển dự án TaskHub được chia thành hai phần chính\u0026mdash; xây dựng hạ tầng AWS serverless và phát triển nền tảng quản lý nhiệm vụ \u0026mdash; mỗi phần bao gồm giai đoạn thực hiện chính như sau:\nKhai báo các giai đoạn phát triển\nGiai đoạn 1: Thiết kế và Lập mô hình (Tháng 1)\nHành động chính: Nghiên cứu Serverless/DevSecOps, lựa chọn các dịch vụ cốt lõi (Lambda, DynamoDB, API Gateway). Thiết kế chi tiết sơ đồ kiến trúc và mô hình dữ liệu NoSQL.\nSản phẩm đầu ra: Sơ đồ Kiến trúc và Tài liệu Mô hình Dữ liệu.\nGiai đoạn 2: Khởi tạo Hạ tầng dưới dạng Mã (Tháng 2)\nHành động chính: Tính toán chi phí vận hành chi tiết. Sử dụng AWS CDK để xây dựng mã nguồn IaC cho các dịch vụ nền tảng (S3, CloudFront, Cognito), đảm bảo khả năng tái tạo môi trường.\nSản phẩm đầu ra: Mã nguồn AWS CDK cơ sở và Báo cáo Chi phí Vận hành.\nGiai đoạn 3: Thiết lập Tự động hóa DevSecOps (Tháng 2\u0026ndash;3)\nHành động chính: Thiết lập CI/CD Pipeline hoàn chỉnh (CodePipeline/CodeBuild). Tích hợp các công cụ AWS CodeGuru và SAST để tự động hóa việc kiểm tra chất lượng và bảo mật mã nguồn trước khi triển khai.\nSản phẩm đầu ra: CodePipeline đã hoạt động và quy trình quét bảo mật tự động.\nGiai đoạn 4: Phát triển và Triển khai (Tháng 3\u0026ndash;4)\nHành động chính: Phát triển chức năng (Lambda Functions với TypeScript) và giao diện (Next.js). Thực hiện Kiểm tra Tích hợp (Integration Testing) giữa các dịch vụ. Triển khai bản chính thức (Production release) qua Pipeline.\nSản phẩm đầu ra: TaskHub Beta Version (hoàn chỉnh CRUD) và Báo cáo Kiểm tra.\nYêu cầu kỹ thuật\nKiến trúc và Công cụ: Toàn bộ hệ thống được khai báo và quản lý bằng AWS CDK để đảm bảo tính nhất quán của hạ tầng.\nCông nghệ: Backend sử dụng TypeScript/Node.js. Giao diện sử dụng Next.js (React).\nQuản lý Mã nguồn: Mã nguồn trên GitLab, triển khai tự động bằng AWS CodePipeline.\nGiám sát: Cấu hình CloudWatch, X-Ray, và CloudWatch Logs để giám sát hiệu suất và gỡ lỗi chuyên sâu.\nYêu cầu Phi chức năng: Hệ thống được đặt tại Singapore (ap-southeast-1) để tối ưu tốc độ tại Việt Nam, có khả năng mở rộng lên 50 người dùng và sử dụng AWS KMS để mã hóa dữ liệu.\n5. Dòng thời gian \u0026amp; Các quan quan trọng Dòng thời gian dự án Trước thực tập (Tháng 0): Chuẩn bị kế hoạch, nghiên cứu DevSecOps và dịch vụ AWS Serverless.\nTháng 1: Thiết lập môi trường phát triển, khởi động hạ tầng AWS và CI/CD đường ống.\nTháng 2: Thiết kế kiến ​​trúc, phát triển chức năng chính và kiểm tra bảo mật tự động.\nTháng 3: Tích hợp frontend \u0026ndash; backend, phát triển thử nghiệm và ra mắt nền tảng.\nSau khi ra mắt: Bảo trì, đánh giá hiệu suất và mở rộng tính năng nâng cao.\n6. Ước tính ngân sách Tài Nguyên Trách Nhiệm Tỷ Lệ (USD) / Giờ Kiến Trúc Sư Giải Pháp [1 người] Thiết kế Kiến trúc Hệ thống, Thiết kế API, Thiết kế Cơ sở dữ liệu, Dẫn dắt Kỹ thuật 6 Kỹ Sư [3 người] Phát triển Backend, Phát triển Frontend, Triển khai Bảo mật 4 Khác (DevOps) [1 người] CI/CD, Triển khai Đám mây, Giám sát, Bảo mật, Cấu hình Bảo mật 4 Giai Đoạn Dự Án Kiến Trúc Sư Giải Pháp Kỹ Sư Khác (Vui lòng chỉ định) Tổng Giờ Thiết kế Hệ thống \u0026amp; Kiến trúc 20 10 0 30 Phát triển Backend 10 80 0 90 Phát triển Frontend 5 60 0 65 Thiết lập Bảo mật \u0026amp; CI/CD 5 30 10 45 Kiểm thử \u0026amp; Triển khai 5 30 0 35 Tổng Giờ 45 210 10 265 Tổng Chi Phí (USD) 270 840 40 800 Phân bổ Đóng góp Chi phí giữa Đối tác, Khách hàng, AWS:\nBên Đóng góp (USD) % Đóng góp trên Tổng thể Khách hàng 0 0 Đối tác 0 0 AWS 800 100 7. Đánh giá rủi ro Ma trận rủi ro\nSự cố mạng hoặc gián đoạn dịch vụ AWS: Tác động trung bình, khả năng trung bình.\nKhai báo CI/CD lỗi: Tác động cao, khả năng thấp.\nVượt qua ngân sách AWS: Tác động trung bình, khả năng thấp.\nLỗi bảo mật: Tác động cao, khả năng trung bình.\nGiảm hiệu suất khi tải tăng: Tác động trung bình, khả năng trung bình.\nGiảm thiểu Chiến lược\nSử dụng AWS đa vùng và giám sát CloudWatch/X-Ray.\nKiểm tra và kiểm tra mã nguồn trước khi khai báo thông qua CodePipeline.\nCài đặt cảnh báo chi phí qua AWS Budgets.\nQuét tự động bảo mật bằng CodeBuild (thay thế cho GitHub Actions).\nKế hoạch dự phòng\nDuy trì môi trường dàn dựng để khôi phục nhanh chóng.\nSử dụng CloudFormation và AWS Backup để sao lưu cấu hình và dữ liệu.\n8. Kết quả mong đợi Cải tiến kỹ thuật\nTự động hóa toàn diện: Chuyển đổi hoàn toàn quy trình phát triển sang mô hình DevSecOps tự động. Thời gian triển khai (Deploy) hệ thống mới chỉ mất dưới 6 phút.\nHiệu suất Đảm bảo: Ứng dụng hoạt động nhanh chóng (API phản hồi dưới 150ms) và ổn định (99.9% Uptime) nhờ kiến trúc Serverless.\nBảo mật Tích hợp: Quét và khắc phục tự động các lỗi bảo mật cấp cao ngay trong quá trình Code Build.\nSẵn sàng Mở rộng: Nền tảng có khả năng mở rộng để phục vụ nhiều người dùng và xử lý lượng truy cập lớn mà không cần thay đổi cấu trúc.\nGiá trị dài hạn\nTạo Tài sản Kỹ thuật: Tạo ra bộ mã AWS CDK/CloudFormation hoàn chỉnh. Đây là khuôn mẫu kiến trúc Serverless đã được tối ưu chi phí, có thể tái sử dụng cho các dự án khác của nhóm.\nNền tảng Vững chắc: Thiết lập môi trường quản lý công việc và phát triển theo tiêu chuẩn công nghiệp (DevSecOps), sẵn sàng cho việc mở rộng tính năng trong tương lai.\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/4-eventparticipated/4.2-event2/","title":"Sự kiện 2","tags":[],"description":"","content":"AWS Cloud Mastery Series #2 – DevOps on AWS 1. Thông tin sự kiện Tên sự kiện: AWS Cloud Mastery Series #2 – DevOps on AWS Thời gian: 8:30 – 17:00 Đơn vị tổ chức: Amazon Web Services (AWS) 2. Mục đích tham dự Tôi tham dự sự kiện nhằm nắm bắt văn hóa và nguyên tắc DevOps trong môi trường cloud, học cách xây dựng CI/CD pipeline hoàn chỉnh, thành thạo Infrastructure as Code với CloudFormation và CDK, tìm hiểu dịch vụ container trên AWS, và học cách triển khai monitoring – observability với CloudWatch và X-Ray.\nNgoài ra, tôi muốn hiểu cách áp dụng DevOps best practices thông qua các case study thực tế.\n3. Tóm tắt nội dung theo Agenda 8:30 – 9:00 — Chào mừng \u0026amp; DevOps Mindset Hoạt động chính:\nCheck-in và ôn tập lại nội dung AI/ML trước đó Giới thiệu văn hóa và nguyên tắc DevOps Các chỉ số quan trọng: DORA, MTTR, tần suất triển khai Vai trò của DevOps trong chuyển đổi số Điểm nổi bật:\nHiểu rằng DevOps không chỉ là công cụ mà là văn hóa làm việc; nắm được các chỉ số đánh giá hiệu quả DevOps và cách ứng dụng trong thực tế doanh nghiệp.\n9:00 – 10:30 — AWS DevOps Services: CI/CD Pipeline Nội dung:\nSource Control với AWS CodeCommit + Git strategies (GitFlow, Trunk-based) Build \u0026amp; Test tự động với CodeBuild Deployment với CodeDeploy: Blue/Green, Canary, Rolling updates Orchestration với CodePipeline Demo: Walkthrough toàn bộ CI/CD pipeline Điểm nổi bật:\nNắm rõ quy trình CI/CD từ source → build/test → deploy, hiểu khác biệt giữa các chiến lược triển khai, và quan sát demo thực tế bằng các DevOps services của AWS.\n10:30 – 10:45 — Nghỉ giải lao Networking và thảo luận cùng chuyên gia AWS và người tham dự.\n10:45 – 12:00 — Infrastructure as Code (IaC) Nội dung:\nCloudFormation: template, stack, drift detection AWS CDK: constructs, reusable patterns Demo triển khai IaC với cả CloudFormation \u0026amp; CDK Thảo luận: nên chọn IaC tool nào? Điểm nổi bật:\nHiểu sâu IaC, so sánh CloudFormation và CDK, và nắm được cách quản lý hạ tầng hiệu quả và có thể tái sử dụng.\n13:00 – 14:30 — Container Services trên AWS Nội dung:\nKiến thức Docker cơ bản Amazon ECR: lưu trữ images, scanning, lifecycle Amazon ECS \u0026amp; EKS: scaling, orchestration, deployment AWS App Runner: triển khai container đơn giản Demo \u0026amp; Case Study: triển khai microservices Điểm nổi bật:\nNắm được kiến thức containerization, phân biệt ECS – EKS, quản lý image với ECR, và trải nghiệm triển khai microservices thực tế.\n14:45 – 16:00 — Monitoring \u0026amp; Observability Nội dung:\nCloudWatch: metric, log, alarm, dashboard AWS X-Ray: distributed tracing, phân tích hiệu năng Demo: thiết lập hệ thống observability hoàn chỉnh Best practices: alerting, dashboard, on-call Điểm nổi bật:\nHiểu cách xây dựng monitoring hiệu quả, tận dụng CloudWatch và X-Ray để phân tích ứng dụng, và áp dụng best practices quan sát hệ thống.\n16:00 – 16:45 — DevOps Best Practices \u0026amp; Case Studies Nội dung:\nChiến lược deployment: feature flag, A/B testing Automated testing kết hợp CI/CD Incident management và postmortems Case studies từ startup và enterprise Điểm nổi bật:\nHiểu chiến lược triển khai nâng cao, quy trình xử lý sự cố bài bản và học hỏi kinh nghiệm từ các case study DevOps thành công.\n16:45 – 17:00 — Q\u0026amp;A \u0026amp; Wrap-up Nội dung:\nLộ trình nghề nghiệp DevOps Roadmap chứng chỉ AWS cho DevOps Engineer Thảo luận mở và giải đáp câu hỏi Những điểm chính rút ra Hiểu rõ văn hóa DevOps và cách triển khai trên AWS Thành thạo CI/CD pipeline với CodeCommit, CodeBuild, CodeDeploy, CodePipeline Nắm chắc IaC với CloudFormation \u0026amp; CDK Hiểu sâu container services (ECR, ECS, EKS, App Runner) Tự thiết lập monitoring với CloudWatch \u0026amp; X-Ray Áp dụng DevOps best practices: deployment strategies, automated testing, incident management Học hỏi từ case studies và demo thực tế Khả năng áp dụng thực tế Xây dựng CI/CD pipeline cho dự án Áp dụng IaC để quản lý hạ tầng nhất quán Triển khai containerization cho microservices Thiết lập monitoring \u0026amp; alerting hiệu quả Áp dụng Blue/Green, Canary deployment Cải thiện quy trình xử lý sự cố và postmortem Trải nghiệm sự kiện Sự kiện “DevOps on AWS” mang lại kiến thức sâu rộng và cực kỳ thực tiễn, giúp tôi hiểu rõ cách triển khai DevOps trong môi trường AWS cloud.\nNhững điểm nổi bật Chuyên gia AWS: giải thích rõ DevOps mindset, hướng dẫn thực tế Hands-on demo: quan sát pipeline từ đầu đến cuối, IaC bằng CloudFormation \u0026amp; CDK Case study thực tế: học hỏi kinh nghiệm triển khai ở startup \u0026amp; enterprise Networking: trao đổi cùng DevOps engineers và Cloud architects Bài học quan trọng DevOps là hành trình liên tục cải tiến IaC là nền tảng để DevOps phát triển bền vững Monitoring \u0026amp; observability là chìa khóa giữ hệ thống ổn định Container là tương lai của application deployment Hình ảnh sự kiện "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Hiểu các kiến thức cơ bản về AWS Virtual Private Cloud Tìm hiểu về bảo mật VPC và các tính năng Multi-VPC Hiểu các kiến thức cơ bản về VPC, DirectConnect, Load Balancer và các tài nguyên bổ sung khác Các nhiệm vụ cần thực hiện trong tuần: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học các kiến thức liên quan đến Virtual Private Cloud - Tường lửa trong VPC - Thực hành: + Tạo VPC, Subnet, Internet Gateway + Tạo Route Table, Security Group + Bật VPC Flow Logs - Triển khai Amazon EC2 Instances 15/09/2025 15/09/2025 https://000003.awsstudygroup.com/1-introduce/ 3 - Thiết lập Hybrid DNS với Route 53 Resolver - Thực hành: + Tạo Key Pair + Khởi tạo CloudFormation Template + Cấu hình Security Group + Kết nối tới RDGW 16/09/2025 16/09/2025 https://000010.awsstudygroup.com/3-connecttordgw/ 4 - Tìm hiểu về VPC Peering và cách thiết lập - Thực hành: + Khởi tạo CloudFormation Template + Tạo Security Group + Tạo EC2 Instance + Cập nhật Network ACL + Cấu hình Route Tables để bật giao tiếp giữa các VPC đã peering + Bật và kiểm tra Cross-Peer DNS 17/09/2025 17/09/2025 https://000019.awsstudygroup.com/6-crosspeerdns/ 5 - Tìm hiểu kiến thức cơ bản về AWS Transit Gateway - Thực hành: + Tạo Transit Gateway + Tạo Transit Gateway Attachments + Tạo Transit Gateway Route Tables + Thêm Transit Gateway Routes vào VPC Route Tables 18/08/2025 18/08/2025 https://000020.awsstudygroup.com/2-prerequiste/ 6 - Tổng hợp kiến thức về nền tảng Networking (VPC, Subnets, Gateways, Routing) - Làm lại một số bài tập về VPC Peering và kết nối các VPC thông qua Transit Gateway 19/08/2025 19/08/2025 Kết quả đạt được trong Tuần 2: Nắm vững nền tảng VPC: Tạo và cấu hình thành công các thành phần cốt lõi của Virtual Private Cloud (VPC): Subnets, Internet Gateway, Route Tables và Security Groups. Triển khai \u0026amp; Giám sát cơ bản: Có kinh nghiệm thực tế trong việc triển khai Amazon EC2 Instances trong môi trường VPC tự tạo. Bảo mật \u0026amp; Giám sát mạng: Áp dụng các nguyên tắc bảo mật bằng cách cấu hình Firewall (Security Groups và Network ACLs) và bật thành công VPC Flow Logs để giám sát lưu lượng. Kết nối Multi-VPC: Thành thạo việc thiết lập và kiểm tra kết nối trong các mô hình mạng phức tạp: VPC Peering: Cấu hình Route Tables và kiểm thử Cross-Peer DNS giữa các VPC. Transit Gateway (TGW): Tìm hiểu và triển khai TGW, quản lý attachments và route tables để kết nối nhiều VPC ở quy mô lớn. Hybrid DNS \u0026amp; Truy cập: Thực hành xây dựng Hybrid DNS sử dụng Route 53 Resolver và cấu hình các phương thức truy cập an toàn (tạo Key Pair, truy cập RDGW) thông qua CloudFormation. Tổng hợp kiến thức: Hệ thống hóa toàn bộ kiến thức Networking trong tuần thông qua các bài tập tích hợp về định tuyến và bảo mật trong hệ thống Multi-VPC. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;S3FullAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:DeleteBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketCORS\u0026#34;, \u0026#34;s3:PutBucketCORS\u0026#34;, \u0026#34;s3:GetBucketWebsite\u0026#34;, \u0026#34;s3:PutBucketWebsite\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:PutBucketVersioning\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::*\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudFrontFullAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudfront:CreateDistribution\u0026#34;, \u0026#34;cloudfront:GetDistribution\u0026#34;, \u0026#34;cloudfront:GetDistributionConfig\u0026#34;, \u0026#34;cloudfront:UpdateDistribution\u0026#34;, \u0026#34;cloudfront:DeleteDistribution\u0026#34;, \u0026#34;cloudfront:ListDistributions\u0026#34;, \u0026#34;cloudfront:CreateInvalidation\u0026#34;, \u0026#34;cloudfront:GetInvalidation\u0026#34;, \u0026#34;cloudfront:ListInvalidations\u0026#34;, \u0026#34;cloudfront:CreateOriginAccessControl\u0026#34;, \u0026#34;cloudfront:GetOriginAccessControl\u0026#34;, \u0026#34;cloudfront:UpdateOriginAccessControl\u0026#34;, \u0026#34;cloudfront:DeleteOriginAccessControl\u0026#34;, \u0026#34;cloudfront:ListOriginAccessControls\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;WAFAndShieldAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;wafv2:CreateWebACL\u0026#34;, \u0026#34;wafv2:GetWebACL\u0026#34;, \u0026#34;wafv2:UpdateWebACL\u0026#34;, \u0026#34;wafv2:DeleteWebACL\u0026#34;, \u0026#34;wafv2:ListWebACLs\u0026#34;, \u0026#34;wafv2:AssociateWebACL\u0026#34;, \u0026#34;wafv2:DisassociateWebACL\u0026#34;, \u0026#34;wafv2:CreateIPSet\u0026#34;, \u0026#34;wafv2:GetIPSet\u0026#34;, \u0026#34;wafv2:UpdateIPSet\u0026#34;, \u0026#34;wafv2:DeleteIPSet\u0026#34;, \u0026#34;wafv2:ListIPSets\u0026#34;, \u0026#34;wafv2:CreateRuleGroup\u0026#34;, \u0026#34;wafv2:GetRuleGroup\u0026#34;, \u0026#34;wafv2:UpdateRuleGroup\u0026#34;, \u0026#34;wafv2:DeleteRuleGroup\u0026#34;, \u0026#34;wafv2:ListRuleGroups\u0026#34;, \u0026#34;shield:DescribeSubscription\u0026#34;, \u0026#34;shield:GetSubscriptionState\u0026#34;, \u0026#34;shield:DescribeProtection\u0026#34;, \u0026#34;shield:ListProtections\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CognitoFullAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cognito-idp:CreateUserPool\u0026#34;, \u0026#34;cognito-idp:DeleteUserPool\u0026#34;, \u0026#34;cognito-idp:DescribeUserPool\u0026#34;, \u0026#34;cognito-idp:ListUserPools\u0026#34;, \u0026#34;cognito-idp:UpdateUserPool\u0026#34;, \u0026#34;cognito-idp:CreateUserPoolClient\u0026#34;, \u0026#34;cognito-idp:DeleteUserPoolClient\u0026#34;, \u0026#34;cognito-idp:DescribeUserPoolClient\u0026#34;, \u0026#34;cognito-idp:UpdateUserPoolClient\u0026#34;, \u0026#34;cognito-idp:ListUserPoolClients\u0026#34;, \u0026#34;cognito-idp:CreateUserPoolDomain\u0026#34;, \u0026#34;cognito-idp:DeleteUserPoolDomain\u0026#34;, \u0026#34;cognito-idp:DescribeUserPoolDomain\u0026#34;, \u0026#34;cognito-idp:AdminCreateUser\u0026#34;, \u0026#34;cognito-idp:AdminDeleteUser\u0026#34;, \u0026#34;cognito-idp:AdminGetUser\u0026#34;, \u0026#34;cognito-idp:ListUsers\u0026#34;, \u0026#34;cognito-identity:CreateIdentityPool\u0026#34;, \u0026#34;cognito-identity:DeleteIdentityPool\u0026#34;, \u0026#34;cognito-identity:DescribeIdentityPool\u0026#34;, \u0026#34;cognito-identity:UpdateIdentityPool\u0026#34;, \u0026#34;cognito-identity:ListIdentityPools\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;APIGatewayFullAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;apigateway:POST\u0026#34;, \u0026#34;apigateway:GET\u0026#34;, \u0026#34;apigateway:PUT\u0026#34;, \u0026#34;apigateway:PATCH\u0026#34;, \u0026#34;apigateway:DELETE\u0026#34;, \u0026#34;apigateway:UpdateRestApiPolicy\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;LambdaFullAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetFunctionConfiguration\u0026#34;, \u0026#34;lambda:ListFunctions\u0026#34;, \u0026#34;lambda:UpdateFunctionCode\u0026#34;, \u0026#34;lambda:UpdateFunctionConfiguration\u0026#34;, \u0026#34;lambda:PublishVersion\u0026#34;, \u0026#34;lambda:CreateAlias\u0026#34;, \u0026#34;lambda:UpdateAlias\u0026#34;, \u0026#34;lambda:DeleteAlias\u0026#34;, \u0026#34;lambda:GetAlias\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:AddPermission\u0026#34;, \u0026#34;lambda:RemovePermission\u0026#34;, \u0026#34;lambda:GetPolicy\u0026#34;, \u0026#34;lambda:PutFunctionConcurrency\u0026#34;, \u0026#34;lambda:DeleteFunctionConcurrency\u0026#34;, \u0026#34;lambda:TagResource\u0026#34;, \u0026#34;lambda:UntagResource\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;DynamoDBFullAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:CreateTable\u0026#34;, \u0026#34;dynamodb:DeleteTable\u0026#34;, \u0026#34;dynamodb:DescribeTable\u0026#34;, \u0026#34;dynamodb:ListTables\u0026#34;, \u0026#34;dynamodb:UpdateTable\u0026#34;, \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:DeleteItem\u0026#34;, \u0026#34;dynamodb:UpdateItem\u0026#34;, \u0026#34;dynamodb:Query\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34;, \u0026#34;dynamodb:BatchGetItem\u0026#34;, \u0026#34;dynamodb:BatchWriteItem\u0026#34;, \u0026#34;dynamodb:DescribeTimeToLive\u0026#34;, \u0026#34;dynamodb:UpdateTimeToLive\u0026#34;, \u0026#34;dynamodb:DescribeContinuousBackups\u0026#34;, \u0026#34;dynamodb:UpdateContinuousBackups\u0026#34;, \u0026#34;dynamodb:TagResource\u0026#34;, \u0026#34;dynamodb:UntagResource\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;KMSAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:CreateKey\u0026#34;, \u0026#34;kms:CreateAlias\u0026#34;, \u0026#34;kms:DeleteAlias\u0026#34;, \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:ListKeys\u0026#34;, \u0026#34;kms:ListAliases\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;kms:GenerateDataKey\u0026#34;, \u0026#34;kms:PutKeyPolicy\u0026#34;, \u0026#34;kms:GetKeyPolicy\u0026#34;, \u0026#34;kms:EnableKey\u0026#34;, \u0026#34;kms:DisableKey\u0026#34;, \u0026#34;kms:ScheduleKeyDeletion\u0026#34;, \u0026#34;kms:CancelKeyDeletion\u0026#34;, \u0026#34;kms:TagResource\u0026#34;, \u0026#34;kms:UntagResource\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;SecretsManagerAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:PutSecretValue\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UntagResource\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CodePipelineAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;codepipeline:CreatePipeline\u0026#34;, \u0026#34;codepipeline:DeletePipeline\u0026#34;, \u0026#34;codepipeline:GetPipeline\u0026#34;, \u0026#34;codepipeline:GetPipelineState\u0026#34;, \u0026#34;codepipeline:UpdatePipeline\u0026#34;, \u0026#34;codepipeline:ListPipelines\u0026#34;, \u0026#34;codepipeline:StartPipelineExecution\u0026#34;, \u0026#34;codepipeline:StopPipelineExecution\u0026#34;, \u0026#34;codepipeline:GetPipelineExecution\u0026#34;, \u0026#34;codepipeline:ListPipelineExecutions\u0026#34;, \u0026#34;codepipeline:TagResource\u0026#34;, \u0026#34;codepipeline:UntagResource\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CodeBuildAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;codebuild:CreateProject\u0026#34;, \u0026#34;codebuild:DeleteProject\u0026#34;, \u0026#34;codebuild:UpdateProject\u0026#34;, \u0026#34;codebuild:BatchGetProjects\u0026#34;, \u0026#34;codebuild:ListProjects\u0026#34;, \u0026#34;codebuild:StartBuild\u0026#34;, \u0026#34;codebuild:StopBuild\u0026#34;, \u0026#34;codebuild:BatchGetBuilds\u0026#34;, \u0026#34;codebuild:ListBuildsForProject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CodeGuruReviewerAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;codeguru-reviewer:AssociateRepository\u0026#34;, \u0026#34;codeguru-reviewer:DescribeRepositoryAssociation\u0026#34;, \u0026#34;codeguru-reviewer:ListRepositoryAssociations\u0026#34;, \u0026#34;codeguru-reviewer:DisassociateRepository\u0026#34;, \u0026#34;codeguru-reviewer:DescribeCodeReview\u0026#34;, \u0026#34;codeguru-reviewer:ListCodeReviews\u0026#34;, \u0026#34;codeguru-reviewer:ListRecommendations\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudFormationAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:CreateStack\u0026#34;, \u0026#34;cloudformation:DeleteStack\u0026#34;, \u0026#34;cloudformation:DescribeStacks\u0026#34;, \u0026#34;cloudformation:UpdateStack\u0026#34;, \u0026#34;cloudformation:ListStacks\u0026#34;, \u0026#34;cloudformation:GetTemplate\u0026#34;, \u0026#34;cloudformation:ValidateTemplate\u0026#34;, \u0026#34;cloudformation:DescribeStackEvents\u0026#34;, \u0026#34;cloudformation:DescribeStackResources\u0026#34;, \u0026#34;cloudformation:ListStackResources\u0026#34;, \u0026#34;cloudformation:CreateChangeSet\u0026#34;, \u0026#34;cloudformation:DeleteChangeSet\u0026#34;, \u0026#34;cloudformation:DescribeChangeSet\u0026#34;, \u0026#34;cloudformation:ExecuteChangeSet\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CloudWatchLogsAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:DeleteLogStream\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34;, \u0026#34;logs:GetLogEvents\u0026#34;, \u0026#34;logs:FilterLogEvents\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;logs:DeleteRetentionPolicy\u0026#34;, \u0026#34;logs:TagLogGroup\u0026#34;, \u0026#34;logs:UntagLogGroup\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;XRayAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;xray:PutTraceSegments\u0026#34;, \u0026#34;xray:PutTelemetryRecords\u0026#34;, \u0026#34;xray:GetSamplingRules\u0026#34;, \u0026#34;xray:GetSamplingTargets\u0026#34;, \u0026#34;xray:GetServiceGraph\u0026#34;, \u0026#34;xray:GetTraceSummaries\u0026#34;, \u0026#34;xray:GetTraceGraph\u0026#34;, \u0026#34;xray:BatchGetTraces\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;SNSAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;sns:CreateTopic\u0026#34;, \u0026#34;sns:DeleteTopic\u0026#34;, \u0026#34;sns:GetTopicAttributes\u0026#34;, \u0026#34;sns:SetTopicAttributes\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;sns:Subscribe\u0026#34;, \u0026#34;sns:Unsubscribe\u0026#34;, \u0026#34;sns:ListSubscriptions\u0026#34;, \u0026#34;sns:ListSubscriptionsByTopic\u0026#34;, \u0026#34;sns:Publish\u0026#34;, \u0026#34;sns:TagResource\u0026#34;, \u0026#34;sns:UntagResource\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;IAMPassRoleForServices\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:PassRole\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;iam:PassedToService\u0026#34;: [ \u0026#34;lambda.amazonaws.com\u0026#34;, \u0026#34;apigateway.amazonaws.com\u0026#34;, \u0026#34;codepipeline.amazonaws.com\u0026#34;, \u0026#34;codebuild.amazonaws.com\u0026#34;, \u0026#34;cloudformation.amazonaws.com\u0026#34; ] } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;IAMRoleManagement\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:UpdateRole\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListRolePolicies\u0026#34;, \u0026#34;iam:ListAttachedRolePolicies\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.8-cognito/5.8.2-password-policies/","title":"Cấu hình Password Policies","tags":[],"description":"","content":"Cấu hình Password Policies Trong bước này, bạn sẽ cấu hình các chính sách mật khẩu để đảm bảo yêu cầu mật khẩu mạnh cho người dùng.\nĐiều hướng đến User Pool của bạn trong Cognito console Vào tab Authentication methods Nhấp Edit trong phần Password policy Cấu hình Password Policy Cấu hình các yêu cầu mật khẩu sau:\nĐộ dài mật khẩu:\nĐộ dài tối thiểu: 8 ký tự Độ dài tối đa: 256 ký tự Độ phức tạp mật khẩu:\n✅ Yêu cầu số ✅ Yêu cầu ký tự đặc biệt ✅ Yêu cầu chữ hoa ✅ Yêu cầu chữ thường Lưu cấu hình Xem lại cài đặt chính sách mật khẩu của bạn Nhấp Save changes Xác minh Password Policy Chính sách mật khẩu hiện đã hoạt động. Người dùng sẽ cần tạo mật khẩu đáp ứng các yêu cầu này:\nVí dụ mật khẩu hợp lệ:\nMySecurePass123! StrongPassword2024# TaskManager@2025 Ví dụ mật khẩu không hợp lệ:\npassword (không có chữ hoa, số, ký tự đặc biệt) 12345678 (không có chữ cái, ký tự đặc biệt) Pass1! (quá ngắn) "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/4-eventparticipated/4.3-event3/","title":"Sự kiện 3","tags":[],"description":"","content":"AWS Cloud Mastery Series #3 – Well-Architected Security Pillar 1. Thông tin sự kiện Tên sự kiện: AWS Cloud Mastery Series #3 – Well-Architected Security Pillar Thời gian: 8:30 – 12:00 Đơn vị tổ chức: Amazon Web Services (AWS) 2. Mục đích tham dự Tôi tham dự sự kiện nhằm nắm vững 5 trụ cột của Well-Architected Security Pillar trên AWS, hiểu các mối đe dọa bảo mật hiện đại, học cách triển khai bảo mật toàn diện từ danh tính, mạng, dữ liệu đến phản ứng sự cố, và áp dụng vào các tình huống thực tế trong doanh nghiệp.\n3. Tóm tắt nội dung theo Agenda 8:30 – 8:50 — Opening \u0026amp; Security Foundation Nội dung chính:\nVai trò của Security Pillar trong Well-Architected Framework Nguyên tắc cốt lõi: Least Privilege – Zero Trust – Defense in Depth Mô hình trách nhiệm chia sẻ (Shared Responsibility Model) Các mối đe dọa bảo mật phổ biến tại doanh nghiệp Việt Nam Điểm nổi bật:\nHiểu nền tảng triết lý bảo mật của AWS, biết cách mô hình trách nhiệm chia sẻ áp dụng vào từng lớp dịch vụ, và nắm được bức tranh tổng quan về rủi ro bảo mật hiện nay.\n8:50 – 9:30 — Trụ cột 1: Identity \u0026amp; Access Management Nội dung chính:\nKiến trúc IAM hiện đại: Users, Roles, Policies Loại bỏ long-term credentials – dùng quyền truy cập tạm thời IAM Identity Center: SSO và permission sets SCP \u0026amp; Permission Boundaries trong quản trị đa tài khoản MFA, credential rotation, Access Analyzer Mini demo: IAM Policy validation Điểm nổi bật:\nNắm vững mô hình IAM hiện đại, hiểu tầm quan trọng của việc loại bỏ long-term credentials, và được trải nghiệm mô phỏng quyền truy cập bằng công cụ validation.\n9:30 – 9:55 — Trụ cột 2: Detection \u0026amp; Continuous Monitoring Nội dung chính:\nCloudTrail logging tập trung GuardDuty threat detection \u0026amp; Security Hub Logging toàn diện: VPC Flow Logs, ALB logs, S3 access logs Alerting \u0026amp; automation với EventBridge Khái niệm Detection-as-Code Điểm nổi bật:\nHiểu chiến lược giám sát đa lớp, cách tự động hóa phát hiện – phản ứng, và lợi ích của việc quản trị rule bảo mật như code.\n9:55 – 10:10 — Nghỉ giải lao Networking cùng chuyên gia bảo mật và AWS SA.\n10:10 – 10:40 — Trụ cột 3: Infrastructure Protection Nội dung chính:\nChiến lược phân tách mạng và cô lập workload Best practice: Public/Private subnet Security Groups vs NACLs Kết hợp WAF + Shield + Network Firewall Bảo mật workload: EC2, ECS, EKS Điểm nổi bật:\nNắm được chiến lược bảo mật mạng theo nhiều lớp, hiểu khi nào dùng SG và NACL, cũng như cách bảo vệ workload trên container và compute.\n10:40 – 11:10 — Trụ cột 4: Data Protection Nội dung chính:\nKMS: key policy, grant, rotation Mã hóa dữ liệu at-rest \u0026amp; in-transit: S3, EBS, RDS, DynamoDB Secrets Manager \u0026amp; Parameter Store: rotation patterns Data classification \u0026amp; access guardrails Điểm nổi bật:\nHiểu rõ các dịch vụ mã hóa, pattern quản lý secrets, và xây dựng hệ thống phân loại – bảo vệ dữ liệu trên AWS.\n11:10 – 11:40 — Trụ cột 5: Incident Response Nội dung chính:\nVòng đời Incident Response theo AWS Playbook thực tế: Lộ IAM credentials S3 public exposure Malware trên EC2 Snapshot, cách ly workload, thu thập evidence Tự động hóa IR bằng Lambda \u0026amp; Step Functions Điểm nổi bật:\nNắm được phản ứng sự cố theo chuẩn AWS, cách tự động hóa phản ứng, và xây dựng SOAR mini trên AWS.\n11:40 – 12:00 — Wrap-Up \u0026amp; Q\u0026amp;A Nội dung chính:\nTổng kết 5 trụ cột Security Các thách thức phổ biến trong doanh nghiệp Việt Nam Lộ trình chứng chỉ: Security Specialty \u0026amp; SA Pro Những điểm chính rút ra Hiểu đầy đủ 5 trụ cột Security của Well-Architected Framework và mối liên kết giữa chúng Thành thạo IAM hiện đại theo nguyên tắc Zero Trust Triển khai monitoring \u0026amp; automated incident response toàn diện Áp dụng chiến lược bảo mật hạ tầng theo nhiều lớp Thành thạo mã hóa, quản lý secrets và bảo vệ dữ liệu Tiếp cận các tình huống bảo mật thực tế theo tiêu chuẩn enterprise Khả năng áp dụng thực tế Đánh giá bảo mật dựa trên 5 Security Pillars Thiết kế lại IAM, loại bỏ long-term credentials Tự động hóa threat detection với GuardDuty – Security Hub – EventBridge Xây dựng network segmentation cho hệ thống hiện tại Triển khai chuẩn mã hóa và phân loại dữ liệu Xây dựng playbook \u0026amp; tự động hóa IR cho các tình huống phổ biến Trải nghiệm sự kiện Tham dự “AWS Cloud Mastery Series #3” mang lại góc nhìn toàn diện về bảo mật cloud và cách triển khai thực tế trong doanh nghiệp.\nCách trình bày của chuyên gia AWS dễ hiểu, trọng tâm và kết hợp nhiều demo minh họa.\nNhững điểm nổi bật Đào tạo chuyên sâu: Trình bày bởi chuyên gia bảo mật AWS giàu kinh nghiệm enterprise Demo thực hành: IAM policy validation, threat detection, incident response Case study thực tế: Các sự cố bảo mật phổ biến và cách xử lý Kiến thức toàn diện: Bao trùm cả 5 trụ cột Security với hướng dẫn chi tiết Bài học quan trọng Bảo mật là quá trình liên tục, không phải cấu hình một lần Zero Trust đòi hỏi thay đổi cách tiếp cận IAM toàn diện Tự động hóa đóng vai trò quan trọng khi hệ thống mở rộng Dữ liệu phải được bảo vệ ở mọi lớp từ hạ tầng đến ứng dụng Hình ảnh sự kiện "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - How Patronus AI Helps Businesses Enhance Reliability When Using Generative AI Blog này giải thích cách Patronus AI giúp các công ty tăng cường sự tin cậy và độ ổn định khi triển khai các hệ thống Generative AI. Bài viết nêu rõ những thách thức mà doanh nghiệp phải đối mặt — chẳng hạn như hiện tượng ảo giác, rủi ro an toàn, thiếu tính minh bạch và khó khăn trong việc đánh giá hiệu năng của mô hình — đồng thời giới thiệu nền tảng đánh giá tự động của Patronus AI được thiết kế để giải quyết những vấn đề này.\nBài viết mô tả cách Patronus sử dụng bộ kiểm thử đối kháng tự động, chấm điểm tự động, hệ thống benchmark (chẳng hạn FinanceBench), và các tính năng giải thích để giúp tổ chức phát hiện điểm yếu của mô hình, giảm thiểu lỗi và đảm bảo đầu ra an toàn, tuân thủ tiêu chuẩn. Bài viết cũng cho thấy cách Patronus tích hợp với các dịch vụ AWS (EKS, SQS, EC2) để xây dựng quy trình đánh giá có khả năng mở rộng.\nTổng thể, blog nhấn mạnh tầm quan trọng của việc kiểm thử AI mạnh mẽ, chuẩn hóa khung đánh giá, cải thiện khả năng giải thích và tăng cường niềm tin cho doanh nghiệp khi ứng dụng Generative AI.\nBlog 2 - Overcoming the Challenges of Kafka Connect with Amazon Data Firehose Blog này giải thích những thách thức vận hành và mở rộng mà khách hàng gặp phải khi dùng Kafka Connect để chuyển dữ liệu streaming từ Amazon MSK đến các hệ thống như Amazon S3. Bài viết mô tả các vấn đề như quá/thiếu tài nguyên xử lý, biến động thông lượng, chi phí vận hành (SDLC, xử lý lỗi, retry) và mức độ khó khăn khi quản lý connector ở quy mô lớn.\nBài viết sau đó giới thiệu tích hợp Amazon Data Firehose với Amazon MSK như một giải pháp serverless, fully managed. Với tích hợp này, khách hàng không cần viết hay vận hành consumer Kafka Connect — Firehose xử lý việc provisioning, scaling, retry, chuyển đổi dữ liệu (ví dụ JSON sang Parquet/ORC) và gửi dữ liệu trực tiếp vào S3. Một tính năng quan trọng được đề cập là khả năng chọn điểm bắt đầu đọc dữ liệu: thời điểm tạo stream, điểm đầu tiên của topic hoặc một timestamp tùy chỉnh.\nBài viết cũng hướng dẫn hai kịch bản:\ndi chuyển từ Kafka Connect sang Firehose xây dựng pipeline MSK → Firehose → S3 mới Bài viết làm rõ cách timestamp tùy chỉnh giúp giảm thiểu trùng lặp và mất mát dữ liệu trong quá trình di chuyển, đồng thời kết luận rằng Firehose mang lại cách tiếp cận đơn giản, tiết kiệm chi phí và độ trễ thấp cho việc đưa dữ liệu từ MSK vào S3 phục vụ phân tích.\nBlog 3 – How Brisa Robotics Uses AWS to Improve Robotics Operations Blog này giải thích cách Brisa Robotics chuyển đổi thiết bị xử lý vật liệu truyền thống thành các đội robot tự động thông minh và dựa trên dữ liệu thông qua các dịch vụ AWS. Bằng cách triển khai AWS IoT Greengrass trên robot, Brisa thu thập dữ liệu cảm biến, truyền dữ liệu đến Amazon Kinesis và Amazon S3, xử lý bằng AWS Lambda và lưu trữ vào Amazon Timestream để phân tích theo thời gian thực.\nBài viết nêu bật cách Brisa xây dựng một pipeline dữ liệu linh hoạt, hoạt động cả khi ngoại tuyến, thích nghi với nhiều môi trường khách hàng khác nhau mà không yêu cầu thay đổi hạ tầng. Với kiến trúc này, Brisa cung cấp dashboard trực quan hiển thị vị trí robot, heatmap, hình ảnh camera và các chỉ số vận hành, giúp khách hàng cải thiện an toàn, hiệu suất và khả năng ra quyết định.\nGiải pháp dựa trên AWS giúp khách hàng của Brisa (một công ty bia lớn toàn cầu) tăng độ chính xác, nâng cao tần suất thu thập dữ liệu, xác định điểm nghẽn và cải thiện hoạt động kho — tất cả mà không cần thay đổi quy trình đang sử dụng.\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Tìm hiểu về Amazon Elastic Compute Cloud và các loại instance. Hiểu một số dịch vụ và cơ chế quản lý tài nguyên trên AWS. Các nhiệm vụ cần thực hiện trong tuần: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Học lý thuyết tổng quát về các khái niệm EC2 và ứng dụng, cùng với các dịch vụ cần thiết để thiết lập một EC2 hoàn chỉnh. 22/09/2025 22/09/2025 3 - Tìm hiểu về khái niệm và ứng dụng của AWS Backup. - Thực hành: + Tạo S3 Bucket + Triển khai hạ tầng + Tạo Backup plan + Thiết lập thông báo + Kiểm thử Restore 23/09/2025 23/09/2025 https://000013.awsstudygroup.com/ 4 - Tìm hiểu về AWS Storage Gateway Thực hành: + Tạo S3 Bucket + Tạo EC2 Storage Gateway + Tạo Storage Gateway + Tạo File Shares + Gắn File Shares lên máy On-premise 24/09/2025 24/09/2025 https://000024.awsstudygroup.com/ 5 - Tìm hiểu kiến thức cơ bản về Amazon Simple Storage Service (Amazon S3): + Độ bền \u0026amp; Hiệu suất + Tính sẵn sàng + Các lớp lưu trữ + Bảo mật + Khả năng mở rộng 25/08/2025 25/08/2025 https://000057.awsstudygroup.com/ 6 - Ôn lại toàn bộ bài học trong tuần (EC2, AWS Backup, Storage Gateway, S3) - Làm lại các bài thực hành để nắm vững hơn - Tổng hợp các kiến thức chính đã học trong tuần 26/09/2025 26/09/2025 Thành tựu đạt được trong Tuần 3: Hiểu các khái niệm cơ bản về EC2 và các loại instance. Thực hành thành công việc thiết lập EC2 và các dịch vụ liên quan. Nắm được các khái niệm và cách sử dụng AWS Backup, đồng thời hoàn thành bài tập backup–restore. Hiểu cách hoạt động của AWS Storage Gateway và thực hành tạo file shares. Học các kiến thức cốt lõi của Amazon S3, bao gồm storage classes, độ bền dữ liệu và bảo mật. Ôn tập và củng cố toàn bộ kiến thức trong tuần thông qua luyện tập và tổng hợp lại nội dung. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.3-lambda/","title":"Lambda","tags":[],"description":"","content":"Khởi tạo Lambda Tạo Lambda Function Chọn Create function → Author from scratch. Trong phần Basic information, cấu hình:\nFunction name: taskhub-backend-1 Runtime: .NET 8 (C#/F#/Powershell) Architecture: arm64 (theo mặc định) Phần Permissions → Change default execution role:\nChọn Create a new role with basic Lambda permissions (AWS sẽ tự tạo role có quyền ghi log vào CloudWatch Logs) Giữ nguyên các cấu hình còn lại và nhấn Create function để hoàn tất. Build Backend \u0026amp; Đóng gói thành file ZIP Do Lambda không cho sửa code trực tiếp với runtime .NET, bạn phải upload file zip.\nTại máy local, build backend bằng lệnh: dotnet publish -c Release -o publish Mở thư mục publish -\u0026gt; Chọn toàn bộ file bên trong, không chọn cả folder.\nNén lại thành file: backend.zip Upload mã nguồn lên Lambda Trong tab Code → chọn Upload from → .zip file. Chọn file backend.zip.\nNhấn Upload và chờ Lambda deploy.\nSau khi upload xong: Code properties sẽ hiển thị package size, SHA256 hash, thời gian cập nhật.\nKiểm tra Runtime Settings Trong phần Runtime settings:\nRuntime: .NET 8\nHandler: YourProject::YourNamespace.YourHandler::FunctionHandler (tùy structure của project)\nArchitecture: rm64\nĐảm bảo Lambda đang chạy đúng entry-point.\nCấu hình Environment Variables Mở tab Configuration → Environment variables Nhấn Edit → Add environment variable Thêm các biến ví dụ: ASPNETCORE_ENVIRONMENT=Production\nDynamoDB_TableName= Your_dynamoDB\nJwt_Secret= Your_JWT_Secret\nNhấn Save.\nCấu hình Timeout \u0026amp; Memory Mở tab Configuration → General configuration\nNhấn Edit\nĐặt:\nMemory: 512MB – 1024MB\nTimeout: 30s (API) hoặc cao hơn nếu cần\nLưu lại.\nThêm Trigger (API Gateway) Để biến Lambda thành API có URL:\nTab Configuration → Triggers\nNhấn Add trigger\nChọn:\nAPI Gateway\nCreate an API\nREST API\nSecurity: Open (hoặc IAM/Authorizer tùy hệ thống)\nNhấn Add "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.8-cognito/5.8.3-email-verification/","title":"Thiết lập Email Verification","tags":[],"description":"","content":"Thiết lập Email Verification Trong bước này, bạn sẽ cấu hình xác minh email để đảm bảo người dùng xác minh địa chỉ email của họ trong quá trình đăng ký.\nĐiều hướng đến User Pool của bạn trong Cognito console Vào tab Sign-up Nhấp Edit trong phần Attribute verification and user account confirmation Cấu hình Email Verification Xác minh thuộc tính và xác nhận tài khoản người dùng:\n✅ Send email message, verify email address Tin nhắn xác minh: Code Chủ đề email xác minh: Xác minh email của bạn cho Task Management System Nội dung email xác minh: Mã xác minh của bạn cho Task Management System là {####}. Vui lòng nhập mã này để hoàn tất đăng ký. Cấu hình Email Delivery Phương thức gửi email:\nSend email with Cognito (cho môi trường phát triển) Địa chỉ email FROM: no-reply@verificationemail.com Lưu ý: Đối với ứng dụng production, hãy xem xét sử dụng Amazon SES để có khả năng gửi email tốt hơn và domain tùy chỉnh.\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/4-eventparticipated/4.4-event4/","title":"Sự kiện 4","tags":[],"description":"","content":"Vietnam Cloud Day 2025 1. Thông tin sự kiện Tên sự kiện: Vietnam Cloud Day 2025 Thời gian: 7:35 – 16:30 Đơn vị tổ chức: Amazon Web Services (AWS) 2. Mục đích tham dự Tôi tham dự sự kiện nhằm cập nhật các xu hướng mới nhất về Điện toán đám mây (Cloud), Generative AI (GenAI) và cách AWS đang xây dựng nền tảng kỹ thuật – dữ liệu – bảo mật giúp doanh nghiệp triển khai AI hiệu quả.\nBên cạnh đó, tôi mong muốn hiểu được cách lãnh đạo doanh nghiệp định hướng AI, từ đó bổ sung định hướng nghề nghiệp cá nhân.\n3. Tóm tắt nội dung theo Agenda 7:35 – 9:00 — Check-in Người tham dự tiến hành check-in và giao lưu trước giờ bắt đầu chương trình.\n9:00 – 9:20 — Khai mạc Phát biểu khai mạc bởi đại diện Chính phủ, nhấn mạnh vai trò của công nghệ số và AI trong chiến lược chuyển đổi số quốc gia.\n9:20 – 9:40 — Bài phát biểu chính Eric Yeo – Country General Manager, AWS Vietnam, Cambodia, Laos \u0026amp; Myanmar\nNội dung chính:\nCam kết đầu tư lâu dài của AWS tại Việt Nam Thúc đẩy phát triển doanh nghiệp nhờ Cloud \u0026amp; GenAI Tiềm năng nhân lực công nghệ tại khu vực 9:40 – 10:00 — Bài phát biểu khách hàng 1 Dr. Jens Lottner – CEO, Techcombank\nCác điểm nổi bật:\nChiến lược \u0026ldquo;AI-first\u0026rdquo; trong ngành ngân hàng Xây dựng năng lực dữ liệu \u0026amp; AI nội bộ Mục tiêu trở thành ngân hàng dẫn đầu công nghệ 10:00 – 10:20 — Bài phát biểu khách hàng 2 Ms. Trang Phung – CEO \u0026amp; Co-Founder, U2U Network\nNội dung:\nKết hợp Blockchain \u0026amp; AI để tạo sản phẩm mới Xây dựng hệ sinh thái Web3 sáng tạo Định hướng phát triển cộng đồng startup 10:20 – 10:50 — Bài phát biểu từ AWS Jaime Valles – VP \u0026amp; GM, Asia Pacific \u0026amp; Japan, AWS\nTập trung vào:\nGenAI là trung tâm của thế hệ ứng dụng tiếp theo Hệ sinh thái dịch vụ AI toàn diện của AWS Mô hình phát triển công nghệ bền vững và bảo mật 11:00 – 11:40 — Phiên thảo luận Navigating the GenAI Revolution: Strategies for Executive Leadership\nModerator: Jeff Johnson (AWS)\nPanelists:\nVũ Văn – CEO ELSA Corp Nguyễn Hòa Bình – Chủ tịch NextTech Dieter Botha – CEO TymeX Điểm nổi bật:\nTư duy lãnh đạo trong kỷ nguyên GenAI Xây dựng văn hoá đổi mới và chấp nhận thay đổi Gắn AI với mục tiêu kinh doanh thay vì chạy theo xu hướng 13:30 – 14:00 — Xây dựng nền tảng dữ liệu thống nhất trên AWS Kien Nguyen – Solutions Architect, AWS\nChiến lược xây dựng nền tảng dữ liệu thống nhất Ingestion → Storage → Processing → Governance Chuẩn bị dữ liệu cho phân tích \u0026amp; AI quy mô lớn 14:00 – 14:30 — Lộ trình và chiến lược ứng dụng GenAI trên AWS Jun Kai Loke \u0026amp; Tamelly Lim – AWS\nNội dung:\nXu hướng GenAI toàn cầu Roadmap AWS: từ hạ tầng tới mô hình Dịch vụ AI trọng điểm: Bedrock, SageMaker, Agents… 14:30 – 15:00 — Vòng đời phát triển phần mềm dựa trên AI (AI-DLC) Binh Tran – Senior Solutions Architect, AWS\nMô hình SDLC mới với AI đóng vai trò cộng tác viên trung tâm AI-driven execution, human supervision Tăng tốc độ phát triển và cải thiện chất lượng sản phẩm 15:30 – 16:00 — Bảo mật ứng dụng Generative AI trên AWS Taiki Dang – Solutions Architect, AWS\nThách thức bảo mật ở 3 lớp: Infrastructure – Model – Application Zero-trust architecture, IAM, encryption mặc định Bảo vệ dữ liệu trong toàn bộ vòng đời AI 16:00 – 16:30 — Vượt xa tự động hóa: AI Agents như động lực tăng năng suất Michael Armentano – Principal WW GTM Specialist, AWS\nAI Agents trở thành “nhân viên kỹ thuật số” Tự học, tự thích nghi, tự triển khai nhiệm vụ phức tạp Tương lai năng suất được nhân bội nhờ AI Những điểm chính rút ra Chiến lược GenAI của AWS từ góc nhìn lãnh đạo đến kỹ thuật Mô hình AI-DLC – xu hướng phát triển phần mềm tương lai Kiến trúc nền tảng dữ liệu phục vụ AI/ML Bảo mật đa lớp trong Generative AI Tiềm năng ứng dụng AI Agents trong doanh nghiệp Tư duy chiến lược trong ứng dụng AI và khả năng kết nối Cloud – Data – AI Khả năng áp dụng thực tế Áp dụng tư duy AI-DLC vào phát triển phần mềm và quy trình DevOps Liên kết bài học về dữ liệu và hạ tầng vào các dự án AI/ML Định hướng nghề nghiệp theo lộ trình Cloud \u0026amp; AI Chuẩn bị kỹ năng cần thiết để tham gia các dự án AI/ML thực tế Vận dụng kiến thức bảo mật đa lớp vào thiết kế hệ thống AI Trải nghiệm sự kiện Tham dự sự kiện mang lại góc nhìn toàn diện về GenAI, Cloud và chiến lược triển khai AI trong doanh nghiệp.\nCác keynote từ AWS và lãnh đạo doanh nghiệp giúp tôi hiểu rõ hơn cách AI được đưa vào vận hành thực tế, cùng những yêu cầu về hạ tầng, dữ liệu và bảo mật.\nNhững điểm nổi bật Nội dung: toàn diện, chất lượng, cập nhật mới nhất từ AWS Diễn giả: chuyên gia cấp cao từ AWS và doanh nghiệp hàng đầu Tổ chức: chuyên nghiệp, chuẩn mực Giá trị: mang lại kiến thức sâu rộng và định hướng rõ ràng về Cloud \u0026amp; AI Bài học quan trọng GenAI cần một nền tảng dữ liệu và bảo mật mạnh mẽ để triển khai thành công Mô hình AI-DLC thay đổi cách thức phát triển phần mềm truyền thống AI Agents sẽ trở thành một phần quan trọng trong năng suất doanh nghiệp Việc áp dụng AI cần gắn với mục tiêu kinh doanh và kiến trúc công nghệ tổng thể Hình ảnh sự kiện "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Học về VM Import/Export và các dịch vụ lưu trữ liên quan. Thực hành quản lý tài nguyên AWS bằng Console và CLI. Các nhiệm vụ cần thực hiện trong tuần: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu về VM Import/Export - Thực hành: + Xuất máy ảo từ On-premises + Tải máy ảo lên AWS + Nhập máy ảo vào AWS + Triển khai EC2 Instance từ AMI 29/09/2025 29/09/2025 https://000014.awsstudygroup.com/ 3 - Xuất instance từ AWS - Thực hành: + Thiết lập ACL cho S3 Bucket + Xuất máy ảo từ Instance + Xuất máy ảo từ AMI 30/09/2025 30/09/2025 https://000014.awsstudygroup.com/ 4 - Tìm hiểu về Amazon FSx for Windows File Server - Thực hành: + Tạo môi trường + Tạo hệ thống file SSD Multi-AZ + Tạo hệ thống file HDD Multi-AZ + Tạo file shares mới + Kiểm tra hiệu năng 01/10/2025 01/10/2025 https://000025.awsstudygroup.com/ 5 - Thực hành: + Giám sát hiệu năng + Bật tính năng data deduplication + Bật shadow copies + Quản lý phiên người dùng và các file đang mở 02/10/2025 02/10/2025 https://000025.awsstudygroup.com/ 6 - Thực hành: + Bật user storage quotas + Bật Continuous Access share + Mở rộng throughput capacity + Mở rộng dung lượng lưu trữ + Xóa môi trường sau khi hoàn thành 03/10/2025 03/10/2025 https://000025.awsstudygroup.com/ Thành tựu đạt được trong Tuần 4: Hiểu và thực hành quy trình VM Import/Export. Xuất và nhập máy ảo thành công thông qua S3 và AMI. Làm việc với Amazon FSx for Windows File Server và tạo được hệ thống file SSD/HDD Multi-AZ. Thực hành chia sẻ file, kiểm tra hiệu năng và sử dụng các tính năng quản lý của FSx. Hoàn thành các tác vụ mở rộng tài nguyên và dọn dẹp toàn bộ* "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.4-apigateway/","title":"API Gateway","tags":[],"description":"","content":"Khởi tạo API Gateway Tạo API Gateway Function Mở API Gateway\nChọn Create API Chọn loại API: REST API\nChọn tiếp: Build\nCấu hình thông tin API Nhập tên API, ví dụ: taskhub-backend-api\nEndpoint type: Regional\nSecurity policy: SecurityPolicy_TLS13_1_3_2025_09\nNhấn Create API\nTạo Resource cho API Trong menu API Gateway, chọn: Resources\nNhấn Create resource\nNhập:\nResource name: auth, task, projects … tùy proeject\nResource path: /auth, /task, …\nNhấn Create resource\nTạo Method và kết nối Lambda Chọn Resource → nhấn **Create method\nChọn: ANY (hoặc POST, GET tùy API)\nIntegration type: Lambda Function\nTick Use Lambda Proxy integration\nChọn Region\nNhập tên function Lambda, ví dụ: taskhub-backend_1\nNhấn Save\nLàm tương tự để tạo API còn lại\nCấp quyền cho API Gateway gọi Lambda Chọn *Deploy API\nTạo stage mới (nếu chưa có): prod1\nNhấn Deploy\nKết quả: Sẽ nhận được Invoke URL dạng: https://ne6pw5hqej.execute-api.ap-southeast-1.amazonaws.com/prod1\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/4-eventparticipated/","title":"Các Sự Kiện Tham Gia","tags":[],"description":"","content":"Sự kiện 1 Tên sự kiện: AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS\nThời gian: 08:00, ngày 15/11/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nNội dung: Workshop giới thiệu tổng quan AI/ML/GenAI trên AWS, thực hành vòng đời Machine Learning với SageMaker, xây dựng GenAI Chatbot bằng Amazon Bedrock, áp dụng Prompt Engineering, RAG, Agents và Guardrails.\nBài học: GenAI cần quy trình hoàn chỉnh, RAG là nền tảng cho chatbot doanh nghiệp, SageMaker chuẩn hóa vòng đời ML, và việc chọn đúng Foundation Model giúp tối ưu hiệu năng và chi phí.\nSự kiện 2 Tên sự kiện: AWS Cloud Mastery Series #2 – DevOps on AWS\nThời gian: 09:00, ngày 17/11/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nNội dung: Tìm hiểu DevOps Mindset, xây dựng CI/CD với CodeCommit, CodeBuild, CodeDeploy, CodePipeline; triển khai hạ tầng bằng CloudFormation \u0026amp; CDK; sử dụng Container (ECR, ECS, EKS); thiết lập Monitoring với CloudWatch \u0026amp; X-Ray.\nBài học: DevOps là văn hóa cải tiến liên tục, IaC là nền tảng quản lý hạ tầng bền vững, Container là xu hướng triển khai ứng dụng, và Monitoring là yếu tố sống còn để vận hành hệ thống ổn định.\nSự kiện 3 Tên sự kiện: AWS Cloud Mastery Series #3 – Well-Architected Security Pillar\nThời gian: 09:00, ngày 29/11/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nNội dung: Giới thiệu 5 trụ cột Well-Architected Security gồm IAM, Detection \u0026amp; Monitoring, Infrastructure Protection, Data Protection và Incident Response; hướng dẫn triển khai bảo mật từ danh tính, mạng, dữ liệu đến tự động hóa phản ứng sự cố bằng các dịch vụ AWS như IAM, GuardDuty, KMS, WAF, CloudWatch, Lambda.\nBài học: Bảo mật là quá trình liên tục, cần áp dụng Zero Trust cho IAM, kết hợp giám sát – tự động hóa để phản ứng nhanh sự cố, và bảo vệ dữ liệu ở mọi lớp từ hạ tầng đến ứng dụng.\nSự kiện 4 Tên sự kiện: AWS Vietnam Cloud Day 2025\nThời gian: 09:00 – 17:30, ngày 18/09/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nNội dung: Cập nhật chiến lược GenAI của AWS, kiến trúc nền tảng dữ liệu phục vụ AI/ML, mô hình phát triển phần mềm AI-DLC, bảo mật đa lớp cho Generative AI và tiềm năng ứng dụng AI Agents trong doanh nghiệp.\nBài học: GenAI cần nền tảng dữ liệu và bảo mật vững chắc, AI-DLC thay đổi cách phát triển phần mềm, AI Agents sẽ thúc đẩy mạnh năng suất, và việc ứng dụng AI phải gắn chặt với mục tiêu kinh doanh.\nSự kiện 5 Tên sự kiện: : AWS GameDay - Generative AI Unicorn Party\nThời gian: 13:30 – 17:00, ngày 14/11/2025\nĐịa điểm: Tầng 26, Bitexco Tower, 02 Hải Triều, Quận 1, TP. Hồ Chí Minh\nVai trò: Người tham dự\nNội dung: Trải nghiệm thực tế AWS Gameday với Amazon Bedrock, Knowledge Base và AI Agents thông qua hình thức trò chơi theo đội, kết hợp trả lời câu hỏi và thực hành trực tiếp trên nền tảng AWS.\nBài học: Hiểu cách ứng dụng Bedrock và Knowledge Base để xây dựng AI Chatbot, đồng thời rèn luyện tư duy giải quyết vấn đề và làm việc nhóm trong môi trường AI thực tế.\nSự kiện 6 Tên sự kiện: Data Science on AWS\nThời gian: 09:30 – 11:45, ngày 16/10/2025\nĐịa điểm: Đại học FPT, Cơ sở Hồ Chí Minh\nVai trò: Người tham dự\nNội dung: Giới thiệu Data Science Pipeline trên AWS (S3 – Glue – SageMaker), demo xử lý dữ liệu với Glue, huấn luyện và triển khai mô hình Sentiment Analysis bằng SageMaker, thảo luận Cloud vs On-premise Data Science.\nBài học: Cloud đóng vai trò cốt lõi trong hệ thống Data Science hiện đại, việc kết hợp S3 – Glue – SageMaker giúp xây dựng pipeline hoàn chỉnh, và thực hành thực tế là yếu tố quan trọng để làm chủ Machine Learning.\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.8-cognito/5.8.4-app-client/","title":"Cấu hình App Client","tags":[],"description":"","content":"Cấu hình App Client Khi tạo User Pool, AWS Cognito đã tự động tạo một App Client mặc định. Trong bước này, chúng ta sẽ cấu hình App Client này để phù hợp với ứng dụng của mình.\nĐiều hướng đến User Pool của bạn trong Cognito console Vào tab App integration Bạn sẽ thấy App Client đã được tạo sẵn Chỉnh sửa App Client Nhấp vào tên App Client để chỉnh sửa Hoặc nhấp Edit nếu có Cập nhật thông tin app client:\nTên app client: TaskManagementWebApp (nếu cần đổi) Loại app client: Public client Luồng xác thực: ✅ ALLOW_USER_PASSWORD_AUTH ✅ ALLOW_REFRESH_TOKEN_AUTH ✅ ALLOW_USER_SRP_AUTH Cấu hình Hosted UI Cài đặt Hosted UI:\nSử dụng Cognito Hosted UI: Enabled Loại domain: Use a Cognito domain Cognito domain: taskmanagement-auth-[your-unique-id] Cài đặt app client ban đầu:\nURL callback được phép: http://localhost:3000/callback https://your-app-domain.com/callback URL đăng xuất được phép: http://localhost:3000/ https://your-app-domain.com/ Cài đặt OAuth 2.0:\nLuồng OAuth được phép: ✅ Authorization code grant ✅ Implicit grant Phạm vi OAuth được phép: ✅ email ✅ openid ✅ profile Lưu cấu hình Xem lại tất cả cấu hình Nhấp Save changes Xác minh cấu hình App Client Sau khi cập nhật, ghi chú lại thông tin quan trọng:\nChi tiết App Client:\nClient ID: [your-client-id] URL Hosted UI: https://taskmanagement-auth-[your-id].auth.us-east-1.amazoncognito.com App Client hiện đã được cấu hình và sẵn sàng để xử lý các yêu cầu xác thực từ ứng dụng của bạn. Bạn có thể sử dụng Client ID và Hosted UI URL để tích hợp với ứng dụng web hoặc mobile của mình.\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/4-eventparticipated/4.5-event5/","title":"Sự kiện 5","tags":[],"description":"","content":"AWS Gameday - Generated AI Unicorn Party 1. Thông tin sự kiện Tên sự kiện: AWS Gameday - Generated AI Unicorn Party Thời gian: 13:30 – 17:00 Đơn vị tổ chức: Amazon Web Services (AWS) 2. Mục đích tham dự Tôi tham dự sự kiện với mong muốn tìm hiểu về các dịch vụ AI của AWS như Bedrock và tham gia vào trò chơi để có trải nghiệm về dịch vụ Bedrock\n3. Tóm tắt nội dung theo Agenda 14h30 – 15:00 — Giới thiệu về AWS Gamedays Nội dung chính:\nGiới thiệu về Gameday và những dịch vụ của AI như Bedrock 15:00 – 15:20 — Hướng dẫn thành viên tham gia sự kiện Nội dung chính:\nCác bạn tham dự sự kiện ngồi giao tiếp và thảo luận với nhau để lập đội Các diễn giả hướng dẫn cách cài đặt môi trường để trải nghiệm gamedays 15:20 – 16:40 — Trò chơi bắt đầu Nội dung chính:\nCác đội bắt đầu truy cập vào trò chơi Trả lời câu hỏi và thực hành dịch vụ của trò chơi yêu cầu để có thể lấy được điểm cho đội 16:40 – 17:00 — Trò chơi bắt đầu Nội dung chính:\nTrao giải cho 3 đội có số điểm cao nhẩt Những điểm chính rút ra Cách sử dụng Bedrock và cách để huấn luyện AI cũng như là cách sử dụng Knowledge base trong AI Agents Khả năng áp dụng thực tế Cách để tạo nên 1 AI chatbox để trả lời câu hỏi dựa trên Knowlegde base được cung cấp Trải nghiệm sự kiện Tham dự “AWS Gameday - Generated AI Unicorn Party” mang lại góc nhìn toàn diện về dịch vụ Bedrock và cách sử dụng, với các bài lab được cung cấp bài bản và môi trường cạnh tranh điểm số giữa các đội chơi mang lại cảm hứng và tiếp thu kiến thức nhanh hơn, với sự hướng dẫn trình bày của diễn giả dễ hiểu trọng tâm kiến thức thông qua các bài tập trong trò chơi\nNhững điểm nổi bật Đào tạo chuyên sâu: Trình bày bởi chuyên gia AWS giàu kinh nghiệm Case study thực tế: Củng cố kiến thức thông qua các câu hỏi thực tế trong trò chơi Kiến thức toàn diện: Cung cấp 1 lượng lớn kiến thức về cách 1 AI Chatbox hoạt động dựa trên KnowLedge Base và các AI Models của AWS Bài học quan trọng Trong môi trường doanh nghiệp thực tế việc ứng dụng AI Agent hiện đang phổ biến đòi hỏi bạn phải có kiến thức về các AI Models để phát triển Luyện tập thông qua các bài học thực tế và luyện tập thông qua nền tảng AWS Hình ảnh sự kiện "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu Tuần 5: Tìm hiểu về Security Hub, tối ưu chi phí bằng Lambda và quản lý tài nguyên bằng Tags và Resource Groups. Hiểu kiểm soát truy cập EC2 dựa trên Tag và khái niệm IAM Permission Boundaries. Các nhiệm vụ cần thực hiện trong tuần: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu về AWS Security Hub - Thực hành: + Bật Security Hub + Xem điểm đánh giá theo từng bộ tiêu chí 06/10/2025 06/10/2025 https://000018.awsstudygroup.com/ 3 - Hiểu cách Lambda hỗ trợ tối ưu chi phí trong môi trường AWS - Thực hành: + Tạo Tag cho Instance + Tạo Role cho Lambda + Tạo Lambda Function + Kiểm tra kết quả 07/10/2025 07/10/2025 https://000022.awsstudygroup.com/ 4 - Tìm hiểu cách quản lý tài nguyên bằng Tags và Resource Groups - Thực hành: + Tạo EC2 Instance kèm tag + Quản lý Tags trên tài nguyên AWS + Lọc tài nguyên theo tag + Sử dụng tags bằng CLI + Tạo Resource Group 08/10/2025 08/10/2025 https://000027.awsstudygroup.com/ 5 - Quản lý truy cập EC2 bằng resource tags thông qua IAM - Thực hành: + Tạo IAM User + Tạo IAM Policy + Tạo IAM Role + Kiểm tra Policy + Switch Role + Kiểm tra lại IAM Policy 09/10/2025 09/10/2025 https://000028.awsstudygroup.com/ 6 - Tìm hiểu về IAM Permission Boundary - Thực hành: + Tạo Limit Policy + Tạo IAM User bị giới hạn quyền + Kiểm tra giới hạn quyền của IAM User 10/10/2025 10/10/2025 https://000030.awsstudygroup.com/ Thành tựu đạt được trong Tuần 5: Biết cách sử dụng AWS Security Hub để giám sát và đánh giá mức độ bảo mật. Hiểu cách Lambda tự động hóa các tác vụ tối ưu chi phí. Biết cách quản lý tài nguyên AWS bằng Tags và Resource Groups. Áp dụng kiểm soát truy cập EC2 bằng resource tags thông qua IAM Policy. Hiểu và áp dụng được IAM Permission Boundaries trong quản lý quyền hạn. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Xây dựng Nền tảng Quản lý Nhiệm vụ với DevOps trên AWS Serverless Tổng quan AWS Serverless cho phép xây dựng và triển khai ứng dụng mà không cần quản lý máy chủ, tự động mở rộng theo nhu cầu và chỉ trả phí cho những gì bạn sử dụng.\nTrong workshop này, chúng ta sẽ học cách thiết kế, xây dựng và triển khai một nền tảng quản lý nhiệm vụ TaskHub hoàn chỉnh sử dụng kiến trúc serverless và quy trình DevSecOps tự động hóa.\nChúng ta sẽ tạo một hệ thống bao gồm frontend, backend API, database và CI/CD pipeline hoàn chỉnh. Workshop tập trung vào ba thành phần chính để xây dựng ứng dụng production-ready trên AWS:\nServerless Backend - Sử dụng AWS Lambda để xử lý nghiệp vụ, API Gateway làm cổng giao tiếp, DynamoDB lưu trữ dữ liệu, và Cognito quản lý xác thực người dùng với chi phí tối ưu.\nContent Delivery - Triển khai ứng dụng Next.js trên S3, phân phối toàn cầu qua CloudFront với độ trễ thấp, và bảo vệ bằng AWS WAF chống các cuộc tấn công web phổ biến.\nDevOps Pipeline - Tự động hóa quy trình build, test và deploy sử dụng CodePipeline và CodeBuild, tích hợp kiểm tra bảo mật với CodeGuru, và quản lý infrastructure as code với CloudFormation.\nNội dung Tổng quan về workshop Chuẩn bị Triển khai hàm phi máy chủ với AWS Lambda Xây dựng Cổng API với Amazon API Gateway Lưu trữ đối tượng đơn giản và bảo mật với Amazon S3 Tăng tốc độ phân phối nội dung với Amazon CloudFront (CDN) Quản lý danh tính và truy cập người dùng với Amazon Cognito Quản lý khóa mã hóa với AWS Key Management Service (KMS) SrcetManager WAF "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/4-eventparticipated/4.6-event6/","title":"Sự kiện 6","tags":[],"description":"","content":"Workshop – Data Science on AWS 1. Thông tin sự kiện Tên sự kiện: Data Science on AWS Thời gian: 09:30 – 11:45, ngày 16/10/2025 Diễn giả: Kha Vân – Cloud Solution Architect AWS, AWS Community Builder Bạch Doãn Vương – DevOps Engineer FPT, AWS Community Builder 2. Mục đích tham dự Tham gia workshop nhằm tìm hiểu cách triển khai Data Science trên nền tảng AWS, từ xử lý dữ liệu, huấn luyện mô hình đến triển khai thực tế, đồng thời hiểu rõ vai trò của Cloud trong các hệ thống Data Science hiện đại.\n3. Tóm tắt nội dung theo Timeline 09:30 – 09:40 | Opening \u0026amp; Goals – Kha Van Nội dung chính:\nGiới thiệu workshop và mục tiêu học tập Giải thích vì sao Data Science cần Cloud 09:40 – 10:05 | Data Science Pipeline on AWS – Kha Van Nội dung chính:\nRecap quy trình Data Science Pipeline: Ingest → Process → Model Mapping sang các dịch vụ AWS: Amazon S3 AWS Glue Amazon SageMaker 10:05 – 10:35 | Demo 1 – Data Processing with Glue – Bach Doan Vuong Nội dung chính:\nImport IMDb dataset Thực hiện: Cleaning dữ liệu Feature Extraction Quan sát kết quả trên Amazon S3 10:35 – 11:00 | Demo 2 – Model Training on SageMaker – Bach Doan Vuong Nội dung chính:\nTrain mô hình Sentiment Analysis Theo dõi metrics Deploy endpoint và test với dữ liệu mẫu 11:00 – 11:35 | Deep Dive \u0026amp; Discussion – Kha Vân Nội dung chính:\nSo sánh Cloud vs On-premise Data Science Phân tích: Hiệu năng Chi phí 11:35 – 11:45 | Homework Project Briefing – Kha Vân Nội dung chính:\nGiới thiệu Workshop Project – Part 1 Thiết kế \u0026amp; mô tả Data Science Pipeline trên AWS cho dataset tự chọn Yêu cầu: Báo cáo 2–3 trang + sơ đồ kiến trúc Những điểm chính rút ra Hiểu rõ quy trình Data Science Pipeline trên AWS Biết cách ứng dụng AWS Glue và SageMaker trong thực tế Khả năng áp dụng thực tế Xây dựng hệ thống: Xử lý dữ liệu Huấn luyện mô hình Triển khai API Machine Learning trên AWS Trải nghiệm sự kiện Workshop mang đến góc nhìn rõ ràng về cách một hệ thống Data Science vận hành trên Cloud. Việc kết hợp giữa lý thuyết và demo thực tế giúp dễ tiếp thu kiến thức và hiểu rõ quy trình triển khai trong môi trường doanh nghiệp.\nNhững điểm nổi bật Workshop có demo thực tế với AWS Glue và Amazon SageMaker Nội dung bám sát Data Science Pipeline hoàn chỉnh trên AWS Diễn giả chia sẻ kinh nghiệm thực tế trong môi trường doanh nghiệp Chia sẽ những khóa học sau buổi workshop giúp sinh viên nắm rõ hơn Bài học quan trọng Hiểu rõ vai trò của Cloud trong các hệ thống Data Science hiện đại Biết cách kết hợp S3 – Glue – SageMaker trong một pipeline hoàn chỉnh Nhận thức được tầm quan trọng của thực hành và triển khai thực tế trong quá trình học Machine Learning Hình ảnh sự kiện "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại [Amazon Web Services Vietnam Co., Ltd.] từ [06/09/2025] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [thảo luận nhóm để xây dựng kiến trúc hạ tầng của dự án, phân tích các dịch vụ và tối ưu chi phí, triển khai các thành phần hạ tầng trên AWS, cấu hình dự án và lập trình tích hợp với các dịch vụ AWS], qua đó cải thiện kỹ năng [thông qua quá trình học tập và trao đổi trong nhóm giúp nâng cao kỹ năng giao tiếp và kiến thức chuyên môn; việc tiếp xúc trực tiếp với các dịch vụ AWS trong dự án thực tế giúp hiểu sâu hơn về cách vận hành; đồng thời quá trình thực hiện dự án cũng giúp cải thiện khả năng lập trình và kỹ năng viết báo cáo].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu Tuần 6: Tìm hiểu các khái niệm cốt lõi về bảo mật và quản lý truy cập trên AWS thông qua KMS và IAM Roles. Hiểu quy trình cơ bản về cơ sở dữ liệu và phân tích dữ liệu với RDS, Glue, Athena và QuickSight. Các nhiệm vụ cần thực hiện trong tuần: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Tìm hiểu cách mã hóa dữ liệu khi lưu trữ (Encrypt at rest) bằng AWS KMS - Thực hành: + Tạo policy, role, group và user + Tạo Key Management Service + Tạo Amazon S3 + Tạo AWS CloudTrail và Amazon Athena - Thực hành: + Kiểm tra và chia sẻ dữ liệu được mã hóa trên S3 13/10/2025 13/10/2025 https://000033.awsstudygroup.com/ 3 - Cấp quyền cho ứng dụng truy cập dịch vụ AWS bằng IAM Role - Thực hành: + Sử dụng Access Key + Tạo IAM Role + Gán IAM Role cho EC2 Instance và kiểm tra hoạt động 14/10/2025 14/10/2025 https://000048.awsstudygroup.com/ 4 - Tìm hiểu về Amazon Relational Database Service (Amazon RDS) - Thực hành: + Thiết lập hạ tầng mạng và các thành phần bảo mật cần thiết cho môi trường database + Tạo EC2 Instance + Tạo RDS Database Instance + Triển khai ứng dụng + Sao lưu và khôi phục 15/10/2025 15/10/2025 https://000005.awsstudygroup.com/ 5 - Tìm hiểu mô hình Data Lake và cách sử dụng - Thực hành: + Tạo IAM Role cho AWS Glue + Tạo S3 Bucket + Tạo Delivery Stream + Tạo dữ liệu mẫu 16/10/2025 16/10/2025 https://000035.awsstudygroup.com/ 6 - Thực hành: + Tạo Data Catalog + Tạo SageMaker Notebook + Tổng quan Amazon Athena + Trực quan hóa dữ liệu bằng QuickSight 17/10/2025 17/10/2025 https://000035.awsstudygroup.com/ Thành tựu đạt được trong Tuần 6: Nắm được cách mã hóa dữ liệu khi lưu trữ bằng AWS KMS và kiểm tra nhật ký CloudTrail. Cấp quyền cho ứng dụng truy cập dịch vụ AWS thông qua IAM Role gán cho EC2. Thiết lập và quản lý cơ sở dữ liệu Amazon RDS, bao gồm sao lưu và khôi phục. Thực hành quy trình Data Lake với AWS Glue, S3, Firehose, Athena, SageMaker Notebook và QuickSight. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.6-s3/","title":"Khởi tạo S3","tags":[],"description":"","content":"WORKLOG ĐỒ ÁN: CẤU HÌNH S3 ORIGIN (FULL) Worklog này bao gồm các bước tạo và cấu hình 2 Amazon S3 Buckets riêng biệt, đóng vai trò là nguồn gốc (Origin) cho các tài nguyên khác nhau của hệ thống: Code Frontend và file do người dùng tải lên.\n1. Cấu Hình S3 Bucket 1: taskhub-frontend-prod (Frontend Origin) Bucket này đóng vai trò là Origin cho CloudFront, chứa code Frontend (HTML, CSS, JS) và các tài sản tĩnh.\n1.1. Truy cập và Khởi tạo Bucket Đăng nhập vào AWS Console, tìm và chọn dịch vụ Amazon S3. Click nút \u0026ldquo;Create bucket\u0026rdquo;. Điền thông tin cấu hình chung: Cấu Hình Giá Trị Giải Thích Bucket name taskhub-frontend-prod Tên Bucket phải là duy nhất. AWS Region Asia Pacific (Singapore) ap-southeast-1 Chọn vùng địa lý gần người dùng mục tiêu nhất để tối ưu hóa độ trễ. 1.2. Cấu hình Object Ownership \u0026amp; Public Access Object Ownership: Chọn ACLs disabled (recommended). Mục đích: Quyền truy cập được quản lý tập trung bằng Bucket Policy, giúp quản lý đơn giản hơn. Block Public Access settings for this bucket: Hành động: Bỏ chọn [ ] Block all public access (và tất cả các tùy chọn con). Lý do: Cho phép chúng ta cấu hình Bucket Policy để cấp quyền đọc chỉ cho CloudFront OAC (Origin Access Control) ở bước sau, đảm bảo S3 có thể hoạt động như một Origin hợp lệ. 1.3. Cấu hình Versioning và Encryption Cấu Hình Giá Trị Giải Thích Bucket Versioning Chọn: Disable Giảm Chi Phí Lưu Trữ vì không cần duy trì nhiều phiên bản của code Frontend. Default encryption Enable Đảm bảo mã hóa dữ liệu khi lưu trữ (at rest). Encryption type Chọn: Server-side encryption with Amazon S3 managed keys (SSE-S3) Phương thức mã hóa mặc định, đơn giản và hiệu quả về chi phí. Bucket Key Chọn: Enable Giảm thiểu chi phí yêu cầu (Request Costs) liên quan đến quá trình mã hóa/giải mã. 2. Cấu Hình S3 Bucket 2: taskhub-files-prod (User Files Storage) Bucket này dùng để lưu trữ các tệp do người dùng tải lên (ảnh, media\u0026hellip;). Ưu tiên bảo mật tối đa. Làm tương tự S3 ở trên.\n2.1. Truy cập và Khởi tạo Bucket Lặp lại các bước tạo Bucket (Mục 1.1). Bucket name: taskhub-files-prod AWS Region: Asia Pacific (Singapore) ap-southeast-1 2.2. Cấu hình Public Access (KHÁC BIỆT BẢO MẬT) Block Public Access settings for this bucket: Giữ nguyên [X] Block all public access (CHỌN TẤT CẢ). Lý do: Đây là Bucket Bảo Mật chứa dữ liệu người dùng. Các tệp KHÔNG ĐƯỢC truy cập công khai. Việc truy cập chỉ được cấp phép tạm thời thông qua Pre-signed URLs được tạo bởi Backend API sau khi xác thực. 2.3. Cấu hình Versioning và Encryption (Tương Tự) Cấu Hình Giá Trị Giải Thích Bucket Versioning Chọn: Disable Ngăn chặn việc tăng chi phí lưu trữ nhanh chóng khi người dùng cập nhật/xóa tệp. Default encryption Enable Bắt buộc phải mã hóa dữ liệu người dùng. Encryption type Chọn: Server-side encryption with Amazon S3 managed keys (SSE-S3) Tiêu chuẩn mã hóa S3. Bucket Key Chọn: Enable Giảm chi phí yêu cầu mã hóa. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.7-cloudfront/","title":"Khởi tạo CloudFront","tags":[],"description":"","content":"CẤU HÌNH CLOUDFRONT DISTRIBUTION HOÀN CHỈNH Worklog này trình bày các bước cấu hình CloudFront Distribution, tập trung vào thiết lập Bảo mật Origin (OAC) và xác nhận các điều kiện tiên quyết trên S3 Bucket.\n1. KIỂM TRA ĐIỀU KIỆN TIÊN QUYẾT S3 Trước khi hoàn tất CloudFront, phải đảm bảo S3 Bucket taskhub-frontend-prod đã được bảo vệ và cấu hình đúng.\n1.1. Static Website Hosting Status Kiểm tra: Tab Properties của S3 Bucket. Trạng thái: S3 static website hosting phải ở trạng thái Disabled. Giải thích: CloudFront là CDN, không cần S3 tự phân phát nội dung. 1.2. Block Public Access \u0026amp; Bucket Policy Kiểm tra: Tab Permissions của S3 Bucket. Block public access (bucket settings): Phải ở trạng thái On (Block all public access). Bucket policy (Xác nhận cuối cùng): Phải chứa Policy OAC đã được CloudFront tự động cập nhật. 2. CẤU HÌNH CLOUDFRONT DISTRIBUTION 2.1. Step 1 \u0026amp; 2: Get started Cấu Hình Giá Trị Giải Thích Hành động Click \u0026ldquo;Create distribution\u0026rdquo;. Bắt đầu quá trình tạo CDN. Kế hoạch Chọn Free Plan ($0/month). Kế hoạch miễn phí cho đồ án. Distribution name taskhub-frontend-cdn Đặt tên dễ nhớ. Distribution type Single website or app. Loại hình phù hợp cho Frontend. 2.2. Step 3: Specify origin (OAC Setup) 1. Chỉ định Origin Origin type: Chọn Amazon S3. S3 origin: Chọn S3 Bucket taskhub-frontend-prod. 2. Thiết lập OAC (Bảo mật Tự động) Tick \u0026ldquo;Allow private S3 bucket access to CloudFront - Recommended\u0026rdquo;. Chọn Use recommended origin settings. Giải thích: Khi hoàn tất tạo Distribution, CloudFront sẽ tự động cập nhật Bucket Policy để cấp quyền truy cập bằng OAC. 3. Cấu hình Cache Cache settings: Chọn Use recommended cache settings tailored to serving S3 content. 2.3. Step 4 \u0026amp; 5: Security \u0026amp; TLS Cấu Hình Giá Trị Áp Dụng Giải Thích WAF Bỏ chọn các tính năng trả phí. Giữ mặc định cho đồ án. Viewer protocol policy Redirect HTTP to HTTPS Bắt buộc sử dụng giao thức an toàn. Custom SSL certificate Default CloudFront Certificate Kích hoạt HTTPS miễn phí. 2.4. Step 6: Review and create 1. Review Origin (Xác nhận nguồn gốc) S3 origin: taskhub-frontend-prod. (Phải đảm bảo đã chọn đúng Bucket Frontend). Grant CloudFront access to origin: Phải là Yes. (Xác nhận OAC hoạt động). 2. Cấu hình Final Price Class: Chọn Use all edge locations (best performance). Click nút \u0026ldquo;Create distribution\u0026rdquo; để triển khai. 3. KIỂM TRA SAU TRIỂN KHAI: XÁC NHẬN BẢO MẬT OAC Sau khi Distribution chuyển sang trạng thái Deploying, bạn thực hiện bước kiểm tra quan trọng này để xác nhận OAC đã hoạt động:\nTruy cập S3 Bucket taskhub-frontend-prod. Vào tab \u0026ldquo;Permissions\u0026rdquo;. Tìm mục \u0026ldquo;Bucket policy\u0026rdquo;. Xác nhận: Policy phải được cập nhật tự động và chứa đoạn JSON ủy quyền cho dịch vụ CloudFront. Điều này chứng tỏ OAC đã khóa truy cập trực tiếp và chỉ cho phép CloudFront đọc tệp . "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc tại FCJ rất thân thiện và thoải mái. Mọi người luôn sẵn sàng hỗ trợ mỗi khi mình gặp khó khăn, thậm chí cả ngoài giờ làm việc. Không gian làm việc được sắp xếp gọn gàng, tạo cảm giác dễ chịu và giúp mình tập trung tốt hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor luôn hướng dẫn rất kỹ và giải thích cặn kẽ mỗi khi mình chưa hiểu, đồng thời khuyến khích mình đặt câu hỏi để mở rộng góc nhìn. Team admin hỗ trợ đầy đủ về thủ tục, tài liệu và luôn tạo điều kiện để mình làm việc thuận lợi. Điều mình đánh giá cao là mentor không đưa ra đáp án ngay, mà để mình tự thử nghiệm và giải quyết vấn đề, giúp mình học được nhiều hơn.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nNhững nhiệm vụ mình được giao bám sát với kiến thức đã học ở trường, đồng thời mở ra nhiều mảng kiến thức mới mà mình chưa từng tiếp cận. Nhờ vậy, mình vừa củng cố được nền tảng, vừa tích lũy thêm nhiều kỹ năng thực hành.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong thời gian thực tập, mình được học thêm nhiều kỹ năng quan trọng như sử dụng công cụ quản lý công việc, kỹ năng phối hợp nhóm và cách giao tiếp chuyên nghiệp trong môi trường doanh nghiệp. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng rõ hơn cho con đường nghề nghiệp sau này.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa làm việc của công ty rất tích cực: mọi người luôn tôn trọng nhau, làm việc nghiêm túc nhưng không thiếu sự vui vẻ. Khi có dự án gấp, các thành viên luôn hỗ trợ lẫn nhau mà không phân biệt vị trí. Điều này khiến mình cảm thấy được hòa nhập và trở thành một phần của tập thể, dù mình chỉ mới là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty hỗ trợ phụ cấp thực tập và linh hoạt trong thời gian làm việc khi mình có nhu cầu. Bên cạnh đó, việc được tham gia các buổi training nội bộ cũng là một lợi ích lớn, giúp mình mở rộng kiến thức và kỹ năng mới.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\n\u0026ndash;\u0026gt; Điều mình hài lòng nhất là môi trường làm việc thân thiện và văn hóa hỗ trợ lẫn nhau. Mentor và các anh chị trong team luôn sẵn sàng giải thích, chia sẻ kinh nghiệm và tạo điều kiện để mình được thử sức vào những nhiệm vụ thực tế.\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\n\u0026ndash;\u0026gt; Theo ý kiến cá nhân của mình, công ty có thể bổ sung thêm các buổi chia sẻ nội bộ hoặc hoạt động kết nối giữa các thực tập sinh, giúp mọi người hiểu nhau hơn và tạo sự gắn kết trong quá trình làm việc.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\n\u0026ndash;\u0026gt; Mình rất khuyến khích bạn của mình thực tập tại công ty nếu có cơ hội. Vì môi trường làm việc chuyên nghiệp, mentor tận tâm và cơ hội học hỏi thực tế rất tốt. Đây là nơi phù hợp để các bạn sinh viên phát triển kỹ năng và trải nghiệm văn hóa doanh nghiệp thực thụ.\nĐề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\n\u0026ndash;\u0026gt; Trong quá trình thực tập tại công ty em thấy có khá ít workshop mà nhóm có thể thực hành chung và chia sẽ kiến thức với nhau, em đề xuất có thêm một vài cuộc thi trả lời đáp án thông qua kahoot hay các phần mềm tương tự giúp các bạn có thể củng cố cũng như nhớ rõ hơn về công dụng dịch vụ của công ty\nBạn có muốn tiếp tục chương trình này trong tương lai?\n\u0026ndash;\u0026gt; Đó là điều chắc chắn. Thực sự mà nói đối với cá nhân em, việc được thực tập tại đây mang lại rất nhiều giá trị thực tiễn và kiến thức thông qua các lab và những buổi sự kiện của công ty. Giúp hiểu rõ và định hướng xu hướng nghề nghiệp của nghề trong tương lai. Môi trường tự do sáng tạo thân thiện và chuyên nghiệp.\nGóp ý khác (tự do chia sẻ):\n\u0026ndash;\u0026gt; bản thân em khá lo lắng khi lần đầu đến công ty nhưng may mắn là các anh chị mentor hổ trợ tụi em rất nhiệt tình. Em hy vọng rằng chương trình sẽ tiếp tục duy trì tinh thần này và mở rộng nó ra hơn nữa để các sinh viên như bọn em có thể phát triển bản thân và kỹ năng.\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Tìm hiểu các dịch vụ về hạ tầng trên AWS. Hiểu cách mà các dịch vụ kết hợp với nhau một cách tối ưu Tìm kiếm chủ đề cho dự án và bước đầu xây dựng kiến trúc cho dự án Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về dịch vụ KMS, mã hóa dữ liệu và cách theo dỗi log 20/10/2025 20/10/2025 3 - Tìm hiểu về cách sử dụng các dịch vụ chung với nhau để xây dựng hạ tầng dự án nhóm 21/10/2025 21/10/2025 4 - Thảo luận nhóm, nghiên cứu để chọn chủ đề cho dự án 22/10/2025 22/10/2025 5 - Chọn chủ đề dự án và bắt đầu tìm hiểu về các dịch vụ cần thiết để xây dựng hạ tầng 23/10/2025 23/10/2025 6 - Xây dựng hạ tầng dự án và hỏi các anh chị mentor góp ý về hạ tầng 24/10/2025 24/10/2025 Kết quả đạt được tuần 7: Hiểu rõ các dịch vụ hạ tầng AWS như KMS, IAM và cách chúng phối hợp để tạo môi trường an toàn và tối ưu. Nắm được cách kết hợp nhiều dịch vụ AWS để xây dựng kiến trúc nền tảng cho một dự án thực tế. Cùng nhóm phân tích và lựa chọn chủ đề dự án phù hợp, xác định các dịch vụ AWS cần sử dụng. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Ôn luyện kiến thức cơ bản để chuẩn bị thi giữa kì Ôn luyện kiến thức thông qua các bài thi AWS Certified Cloud Partitioner (CLF-C02-English) Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Bắt đầu ôn luyện các kiến thức về các dịch vụ cơ bản của AWS 27/10/2025 27/10/2025 3 - Làm các bài thi trực tuyến thông qua web skill builder 28/10/2025 28/10/2025 4 - Chỉnh sửa chủ đề dự án vì không phù hợp, thảo luận để tìm ra chủ đề mới và các dịch vụ đi kèm 29/10/2025 29/10/2025 5 - Tiếp tục ôn luyện kiến thức cho kì thi giữa kì thông qua skill builder và Youtube 30/10/2025 30/10/2025 6 - Luyện đề 31/10/2025 31/10/2025 Kết quả đạt được tuần 8: Ôn tập lại toàn bộ kiến thức nền tảng về các dịch vụ AWS, giúp củng cố hiểu biết trước khi bước vào kỳ thi. Hoàn thành nhiều bài luyện tập trên AWS Skill Builder, nắm rõ dạng câu hỏi và cách áp dụng kiến thức vào tình huống thực tế. Cùng nhóm xem xét lại chủ đề dự án, phát hiện sự không phù hợp và đề xuất được hướng triển khai mới cùng các dịch vụ AWS liên quan. Tăng cường luyện đề qua Skill Builder và các nguồn trên YouTube, cải thiện tốc độ làm bài và khả năng phân tích câu hỏi. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.8-cognito/","title":"Thiết lập AWS Cognito Authentication","tags":[],"description":"","content":"Workshop AWS Cognito User Authentication Tổng quan AWS Cognito cung cấp quản lý danh tính và truy cập người dùng cho các ứng dụng web và mobile. Nó cho phép bạn thêm tính năng đăng ký, đăng nhập và kiểm soát truy cập vào ứng dụng một cách nhanh chóng và dễ dàng.\nTrong workshop này, bạn sẽ học cách:\nTạo và cấu hình Cognito User Pool Thiết lập chính sách mật khẩu và xác minh email Cấu hình App Client với Hosted UI Triển khai xác thực email/mật khẩu cơ bản Nội dung Tạo Cognito User Pool Cấu hình Password Policies Thiết lập Email Verification Cấu hình App Client "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.9-keymanagementservice/","title":"Thiếp lập KMS","tags":[],"description":"","content":"Mục tiêu Tạo Customer Managed Key (CMK) trên AWS KMS để:\nMã hóa dữ liệu trong DynamoDB Mã hóa Secrets Manager Đảm bảo tiêu chuẩn DevSecOps – dữ liệu được mã hóa bằng KMS Bước 1 – Truy cập AWS Key Management Service (KMS) Đăng nhập AWS Console Tìm dịch vụ: KMS Chọn Key Management Service Vào menu Customer managed keys Click Create a key Bước 2 – Cấu hình khóa (Configure Key) Tại Key type, chọn Symmetric Tại Key usage, chọn Encrypt and decrypt Các tùy chọn khác giữ mặc định Click Next Bước 3 – Thêm nhãn (Alias \u0026amp; Mô tả) Alias Nhập:\ntaskhub_kms Click Next\nBước 4 – Phân quyền quản trị khóa (Key Administrative Permissions) Trong danh sách Key administrators, chọn QuocBao Giữ nguyên tùy chọn Allow key administrators to delete this key Click Next User được chọn ở bước này có toàn quyền quản trị KMS Key:\nChỉnh sửa policy Kích hoạt / vô hiệu hóa key Xóa key Bước 5 – Phân quyền sử dụng khóa (Key Usage Permissions) Trong danh sách Key users, chọn QuocBao Không cần thêm Other AWS accounts Click Next Bước 6 – Chỉnh sửa chính sách khóa (Edit Key Policy) Tại bước Edit key policy, click Edit Kiểm tra policy phải có đầy đủ các nhóm quyền sau: Root account: kms:* User QuocBao được phép quản trị key và sử dụng key { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;key-consolepolicy-3\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Enable IAM User Permissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::166557634525:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;kms:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow access for Key Administrators\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::166557634525:user/QuocBao\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Create*\u0026#34;, \u0026#34;kms:Describe*\u0026#34;, \u0026#34;kms:Enable*\u0026#34;, \u0026#34;kms:List*\u0026#34;, \u0026#34;kms:Put*\u0026#34;, \u0026#34;kms:Update*\u0026#34;, \u0026#34;kms:Revoke*\u0026#34;, \u0026#34;kms:Disable*\u0026#34;, \u0026#34;kms:Get*\u0026#34;, \u0026#34;kms:Delete*\u0026#34;, \u0026#34;kms:TagResource\u0026#34;, \u0026#34;kms:UntagResource\u0026#34;, \u0026#34;kms:ScheduleKeyDeletion\u0026#34;, \u0026#34;kms:CancelKeyDeletion\u0026#34;, \u0026#34;kms:RotateKeyOnDemand\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow use of the key\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::166557634525:user/QuocBao\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:DescribeKey\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow attachment of persistent resources\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::166557634525:user/QuocBao\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:CreateGrant\u0026#34;, \u0026#34;kms:ListGrants\u0026#34;, \u0026#34;kms:RevokeGrant\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;kms:GrantIsForAWSResource\u0026#34;: \u0026#34;true\u0026#34; } } } ] } Chỉnh sửa nội dung policy nếu cần cho đúng ARN tài khoản Click Next AWS sẽ tự động gắn policy hợp lệ cho key.\nBước 7 – Kiểm tra \u0026amp; Hoàn tất (Review \u0026amp; Finish) Kiểm tra lại toàn bộ cấu hình: Mục Giá trị Key type Symmetric Key usage Encrypt and decrypt Alias taskhub_kms Key Admin QuocBao Key User QuocBao Click Finish AWS bắt đầu khởi tạo KMS Key.\nBước 8 – Xác nhận tạo KMS Key thành công Sau khi tạo thành công, truy cập lại KMS → Customer managed keys Kiểm tra thông tin: Alias: taskhub_kms Status: Enabled Key type: Symmetric Key spec: SYMMETRIC_DEFAULT Key usage: Encrypt and decrypt Như vậy KMS Key đã được tạo thành công.\n"},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Chỉnh sửa và xây dựng kiến thúc về chủ đề mới Phân công công việc dự án Tìm hiểu về DynamoDB Local và các dịch vụ bảo mật của AWS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Bắt đầu triển khai dự án 03/11/2025 03/11/2025 3 - Tìm hiểu cách sử dụng và vận hành cảu DynamoDB Local 04/11/2025 04/11/2025 https://000078.awsstudygroup.com/3-write-data-to-dynaomodb/ 4 - Phát triển dự án 05/11/2025 05/11/2025 5 - Thảo luận về dự án và tìm hiểu các dịch vụ về bảo mật như KMS, Cognito và WAF 06/11/2025 06/11/2025 6 - Tiếp tục phát triển dự án 07/11/2025 07/11/2025 Kết quả đạt được tuần 9: Hoàn thiện và điều chỉnh lại chủ đề dự án, nắm rõ phạm vi và yêu cầu kỹ thuật. Phân chia nhiệm vụ trong nhóm, xác định rõ vai trò và phần việc của từng thành viên. Hiểu cách cài đặt, vận hành và tích hợp DynamoDB Local vào môi trường phát triển. Tìm hiểu và nắm được vai trò của các dịch vụ bảo mật AWS như KMS, Cognito, WAF trong việc xây dựng hệ thống an toàn. "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Week 8 Objectives: Tiếp tục phát triển dự án, giao diện web Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Phát triển dự án 10/11/2025 10/11/2025 3 - Phát triển dự án 11/11/2025 11/11/2025 4 - Phát triển dự án 12/11/2025 12/11/2025 5 - Phát triển dự án 13/11/2025 13/11/2025 6 - Phát triển dự án 14/11/2025 14/11/2025 Kết quả đạt được tuần 10: Tiếp tục triển khai dự án "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Tiếp tục phát triển dự án, giao diện web Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Phát triển dự án 17/11/2025 17/11/2025 3 - Phát triển dự án 18/11/2025 18/11/2025 4 - Phát triển dự án 19/11/2025 19/11/2025 5 - Phát triển dự án 20/11/2025 20/11/2025 6 - Phát triển dự án 21/11/2025 21/11/2025 Kết quả đạt được tuần 11: Tiếp tục triển khai dự án "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Tiếp tục phát triển dự án và triển khai trên dịch vụ của AWS Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Phát triển dự án và triển khai dự án trên AWS 27/10/2025 27/10/2025 3 - Phát triển dự án và triển khai dự án trên AWS 28/10/2025 28/10/2025 4 - Phát triển dự án và triển khai dự án trên AWS 29/10/2025 29/10/2025 5 - Phát triển dự án và triển khai dự án trên AWS 30/10/2025 30/10/2025 6 - Phát triển dự án và triển khai dự án trên AWS 31/10/2025 31/10/2025 Kết quả đạt được tuần 12: Phát triển dự án và bắt đầu đẩy dự án từ local sang trên cloud "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.17-secretmanager/","title":"Cấu hình AWS Secrets Manager","tags":[],"description":"","content":"Mục tiêu Sử dụng AWS Secrets Manager để lưu trữ cấu hình/secret cho hệ thống TaskHub với các yêu cầu:\nSecret được lưu dưới dạng JSON (Key/value pairs – Plaintext) Dữ liệu được mã hóa bằng KMS CMK: taskhub_kms (Tùy chọn) Bật tự động xoay vòng secret (rotation) bằng AWS Lambda Bước 1 – Truy cập AWS Secrets Manager Tại AWS Console, nhập vào ô tìm kiếm: Secrets Manager. Chọn dịch vụ Secrets Manager trong danh sách Services. Bước 2 – Tạo secret mới (Key/value pairs – JSON) Tại trang chính của Secrets Manager, click Store a new secret. Ở mục Secret type, chọn: Other type of secret.\nTại khu vực Key/value pairs:\nChuyển từ tab Key/value sang tab Plaintext. Dán nội dung JSON sau (demo cho DynamoDB + KMS): { \u0026#34;Service\u0026#34;: \u0026#34;Amazon DynamoDB\u0026#34;, \u0026#34;Table\u0026#34;: \u0026#34;TaskHub Tables\u0026#34;, \u0026#34;Encryption\u0026#34;: \u0026#34;SSE-KMS\u0026#34;, \u0026#34;KMSKeyAlias\u0026#34;: \u0026#34;taskhub_kms\u0026#34;, \u0026#34;Purpose\u0026#34;: \u0026#34;Store users, projects, tasks\u0026#34;, \u0026#34;DataProtection\u0026#34;: \u0026#34;Encrypted at rest\u0026#34; } Tại mục Encryption key, chọn khóa KMS:\ntaskhub_kms Click Next.\nBước 3 – Cấu hình tên secret và thông tin cơ bản Tại bước Configure secret:\nSecret name:\nVí dụ:\nprod/taskhub/secretmanager\nDescription (không bắt buộc):\nMetadata for TaskHub DynamoDB encryption demo\nTags (optional): bỏ qua cho workshop.\nResource permissions (optional): giữ mặc định (phân quyền bằng IAM).\nReplicate secret (optional): không bật trong workshop.\nClick Next.\nBước 4 – Cấu hình tự động xoay secret (Rotation – tùy chọn) Trong môi trường production, secret thường được xoay vòng theo chu kỳ 30 ngày.\nTrong workshop, ta cấu hình thời gian ngắn để demo.\nTại bước Configure rotation – optional, bật: Automatic rotation Trong Rotation schedule: Chọn Schedule expression builder Time unit: Hours Hours: 23 (Tùy chọn) Window duration: 4h Giữ tick Rotate immediately when the secret is stored Tại Rotation function: Chọn Lambda function: taskhub-backend Click Next. Bước 5 – Kiểm tra \u0026amp; lưu secret Tại bước Review, kiểm tra lại các thông tin:\nSecret type: Other type of secret Encryption key: taskhub_kms Secret name: prod/taskhub/metadata Automatic rotation: Enabled Lambda rotation function: taskhub-backend Kéo xuống phần Sample code:\nAWS sẽ hiển thị sẵn hàm mẫu getSecret() cho các ngôn ngữ như: Java JavaScript Python C# Go Backend của TaskHub sẽ sử dụng SDK tương ứng để gọi Secrets Manager thay vì hard-code cấu hình trong source code. Click Store để hoàn tất.\nKết quả đạt được Secret mới đã được tạo trong AWS Secrets Manager. Nội dung secret được lưu dưới dạng JSON. Secret được: Mã hóa at-rest bằng KMS (taskhub_kms) Có thể tự động xoay vòng bằng Lambda Backend của TaskHub có thể truy xuất secret thông qua: AWS SDK IAM Role / Policy "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/5-workshop/5.18-waf/","title":"Cấu hình Web ACL","tags":[],"description":"","content":"Bước 1 – Truy cập AWS WAF \u0026amp; Shield Đăng nhập AWS Console Tìm dịch vụ: WAF \u0026amp; Shield Click AWS WAF\nMenu trái chọn:\nProtection packs (web ACLs)\nClick nút:\nCreate protection pack (web ACL)\nBước 2 – Chọn loại ứng dụng (Tell us about your app) 2 Chọn App category API \u0026amp; integration services\nBước 3 – Chọn CloudFront cần bảo vệ Mở Select resources to protect Click Add resources Chọn:\nGlobal → Add CloudFront or Amplify resources Tick CloudFront của TaskHub (S3 frontend) Click Add --- Bước 4 – Chọn kiểu Rule Pack Chọn: ✅ Build your own pack from all of the protections AWS WAF offers\nCột bên phải chọn: ✅ AWS-managed rule group\nClick Next --- Bước 5 – Thêm Amazon IP Reputation List Chọn rule: Trong Rule overrides, set: Rule Action AWSManagedIPReputationList ✅ Block AWSManagedReconnaissanceList ✅ Block AWSManagedIPDDoSList ✅ Count Click Add rule ✅ Sau bước này rule hiển thị trong danh sách Add rules\nBước 6 – Kiểm tra danh sách rule đã thêm Kiểm tra thấy:\nRule: AWSManagedRulesAmazonIpReputationList Trạng thái: Saved WCU: 25 WCU --- Bước 7 – Đặt tên Web ACL Trong mục Name and describe:\nName: taskhub-waf Description: (bỏ trống hoặc nhập tùy ý) Bước 8 – Tạo Protection Pack (Web ACL) Click: Create protection pack (web ACL)\nĐợi AWS tạo Web ACL hoàn tất "},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://nguyenquocbaoily.github.io/fcj-workshop-template/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]